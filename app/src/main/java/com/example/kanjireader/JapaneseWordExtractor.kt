package com.example.kanjireader

import android.util.Log


class JapaneseWordExtractor {

    companion object {
        private const val TAG = "JapaneseWordExtractor"

        // Japanese character ranges
        private val HIRAGANA_RANGE = Regex("[\u3040-\u309F]")
        private val KATAKANA_RANGE = Regex("[\u30A0-\u30FF]")
        private val KANJI_RANGE = Regex("[\u4E00-\u9FAF]")
        private val JAPANESE_CHAR = Regex("[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]")

        // Pattern to match Japanese words (sequences of Japanese characters)
        private val JAPANESE_WORD_PATTERN = Regex("[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]+")
        
        // Pattern to match romaji words (sequences of Latin letters)
        private val ROMAJI_WORD_PATTERN = Regex("[a-zA-Z]+")
        
        // Pattern to match mixed script sequences (Japanese + romaji together)
        private val MIXED_SCRIPT_PATTERN = Regex("[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAFa-zA-Z]+")
    }

    private val romajiConverter = RomajiConverter()
    

    /**
     * Extract Japanese words from OCR text instead of individual kanji
     */
    // Update extractJapaneseWords method in JapaneseWordExtractor.kt
    // Update extractJapaneseWords method in JapaneseWordExtractor.kt
    // Update extractJapaneseWords method in JapaneseWordExtractor.kt
    fun extractJapaneseWords(text: String): Set<String> {
        val words = mutableSetOf<String>()

        // Find all Japanese word sequences
        val matches = JAPANESE_WORD_PATTERN.findAll(text)

        for (match in matches) {
            val word = match.value

            // Add the full word if it's reasonable length
            if (word.length >= 1) {
                words.add(word)

                // Add individual kanji characters for single-character lookups
                for (char in word) {
                    if (isKanji(char.toString())) {
                        words.add(char.toString())
                    }
                }
            }
        }

        return words
    }


    // Add helper function to check if a character is kanji
    private fun isKanji(char: String): Boolean {
        if (char.isEmpty()) return false
        val codePoint = char.codePointAt(0)
        return (codePoint in 0x4E00..0x9FAF) || (codePoint in 0x3400..0x4DBF)
    }

    /**
     * Extract Japanese words with their positions in the text
     * Returns a list of WordPosition objects containing word and position info
     */
    fun extractJapaneseWordsWithPositions(text: String): List<WordPosition> {
        val words = mutableListOf<WordPosition>()

        // Find all Japanese word sequences with their positions
        val matches = JAPANESE_WORD_PATTERN.findAll(text)

        for (match in matches) {
            val word = match.value
            val startPos = match.range.first
            val endPos = match.range.last + 1

            // Add the full word if it's reasonable length
            if (word.length >= 1) {
                words.add(WordPosition(word, startPos, endPos))

                // For multi-character words, also add individual kanji
                if (word.length > 1) {
                    var currentPos = startPos
                    for (char in word) {
                        if (isKanji(char.toString())) {
                            words.add(WordPosition(char.toString(), currentPos, currentPos + 1))
                        }
                        currentPos++
                    }
                }
            }
        }

        return words
    }

    /**
     * Data class to hold word and its position information
     */
    data class WordPosition(
        val word: String,
        val startPosition: Int,
        val endPosition: Int,
        val sequenceId: Int = 0,  // Unique identifier for this word instance
        val kuromojiToken: com.atilika.kuromoji.ipadic.Token? = null,  // Store original Kuromoji token
        val baseForm: String? = null  // Base form for dictionary lookup
    ) {
        // Get the base form from either the explicit field or the Kuromoji token
        fun getBaseFormForLookup(): String {
            return baseForm ?: kuromojiToken?.baseForm ?: word
        }
    }

    /**
     * Clean OCR text and normalize common OCR errors
     */
    fun cleanOCRText(text: String): String {
        val cleaned = text
            // Remove non-Japanese characters except common punctuation
            .replace(Regex("[^\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FAF\\s\\n.,!?()\\-:Ôºö‚Äª„ÄÇ„ÄÅ0-9]"), "")
            // Normalize common OCR mistakes
            .replace("Ôºê", "0")
            .replace("Ôºë", "1")
            .replace("Ôºí", "2")
            .replace("Ôºì", "3")
            .replace("Ôºî", "4")
            .replace("Ôºï", "5")
            .replace("Ôºñ", "6")
            .replace("Ôºó", "7")
            .replace("Ôºò", "8")
            .replace("Ôºô", "9")
            // Common OCR character mistakes (based on your log)
            .replace("Èπø", "ËÉΩ") // OCR often mistakes ËÉΩ for Èπø
            .replace("ÁÜä", "ËÉΩ") // Another common mistake
            .replace("Èô∫", "È®ì") // Èô∫ -> È®ì
            .replace("Èô§", "Ê•≠") // Èô§ -> Ê•≠
            .replace("ËºÉ", "Ë®≠") // ËºÉ -> Ë®≠
            // Normalize whitespace
            .replace(Regex("\\s+"), " ")
            .trim()

        return cleaned
    }

    /**
     * Check if a string contains Japanese characters
     */
    fun containsJapanese(text: String): Boolean {
        return JAPANESE_CHAR.containsMatchIn(text)
    }

    /**
     * Check if a string contains kanji
     */
    fun containsKanji(text: String): Boolean {
        return text.any { char -> KANJI_RANGE.matches(char.toString()) }
    }
    
    /**
     * Extract words from mixed script text (Japanese + romaji)
     * Example: "ÂõΩË™ûwo„Åπ„Çì„Åç„Çá„ÅÜshiteimasu" -> ["ÂõΩË™û", "wo", "„Åπ„Çì„Åç„Çá„ÅÜ", "shiteimasu"]
     */
    fun extractMixedScriptWords(text: String): Set<String> {
        val words = mutableSetOf<String>()
        
        
        // First, extract pure Japanese words
        val japaneseMatches = JAPANESE_WORD_PATTERN.findAll(text)
        for (match in japaneseMatches) {
            val word = match.value
            words.add(word)
            
            // Only add individual kanji characters for dictionary lookup
            for (char in word) {
                if (isKanji(char.toString())) {
                    words.add(char.toString())
                }
            }
        }
        
        // Extract romaji words and convert them to hiragana
        val romajiMatches = ROMAJI_WORD_PATTERN.findAll(text)
        for (match in romajiMatches) {
            val romajiWord = match.value
            
            // Add original romaji word
            words.add(romajiWord)
            
            // Convert to hiragana and add
            val hiraganaWord = romajiConverter.toHiraganaWithParticles(romajiWord)
            if (hiraganaWord != romajiWord) {
                words.add(hiraganaWord)
            }
        }
        
        return words
    }
    
    /**
     * Convert mixed script text to pure Japanese
     * Example: "ÂõΩË™ûwo„Åπ„Çì„Åç„Çá„ÅÜshiteimasu" -> "ÂõΩË™û„Çí„Åπ„Çì„Åç„Çá„ÅÜ„Åó„Å¶„ÅÑ„Åæ„Åô"
     */
    fun convertMixedScriptToJapanese(text: String): String {
        return romajiConverter.convertMixedScript(text)
    }
    

    /**
     * Check if text contains romaji characters
     */
    fun containsRomaji(text: String): Boolean {
        return romajiConverter.containsRomaji(text)
    }
    
    /**
     * Extract words from text that may contain both Japanese and romaji
     */
    fun extractAllWords(text: String): Set<String> {
        return if (containsRomaji(text)) {
            extractMixedScriptWords(text)
        } else {
            extractJapaneseWords(text)
        }
    }

    /**
     * Extract words from text using Kuromoji morphological analyzer
     * This provides proper Japanese word segmentation
     * 
     * @param text The text to extract words from
     * @param repository The dictionary repository (optional, for filtering)
     * @return List of word positions from Kuromoji tokenization
     */
    suspend fun extractWordsWithKuromoji(
        text: String,
        repository: DictionaryRepository? = null
    ): List<WordPosition> {
        val results = mutableListOf<WordPosition>()
        // Note: Removed „ÅØ, „ÇÇ, „Åß from this list as they need special handling
        val particles = setOf("„Çí", "„Åå", "„Å´", "„Å®", "„ÅÆ", "„Å∏", "„ÇÑ", "„Åã", "„Å≠", "„Çà", "„Çè", "„Åû", "„Å™", "„Å†", "„Åß„Åô", "„Åì„ÅÆ", "„Åù„ÅÆ", "„ÅÇ„ÅÆ", "„Å©„ÅÆ")
        // Removed "„Åæ„Åô" from particles so it can be grouped with verbs
        
        // First, handle middle dot separators in compound words
        val textWithSplitCompounds = splitCompoundWords(text)
        
        // Preprocess text to remove spaces within Japanese words
        val processedText = reconnectJapaneseWords(textWithSplitCompounds)
        
        
        
        // Declare tokens outside try block so it's available for grouping
        val tokens: List<com.atilika.kuromoji.ipadic.Token>
        
        try {
            // Use Kuromoji tokenizer to segment the processed text
            val tokenizer = com.atilika.kuromoji.ipadic.Tokenizer()
            tokens = tokenizer.tokenize(processedText)
            
            // Debug: Check if we have problematic words in the text to debug tokenization
            if (processedText.contains("ËÄÉ„Åà") || processedText.contains("Âêç‰ªò„Åë")) {
                Log.d("KuromojiDebug", "Processed text: '$processedText'")
                Log.d("KuromojiDebug", "Raw tokens from Kuromoji (${tokens.size} tokens):")
                tokens.forEachIndexed { index, token ->
                    Log.d("KuromojiDebug", "Token $index: '${token.surface}' (${token.partOfSpeechLevel1},${token.partOfSpeechLevel2}) baseForm='${token.baseForm}' conjugation='${token.conjugationForm}'")
                }
            }
            
            var currentPosition = 0
            var sequenceId = 0  // Unique identifier for each word
            val skippedTokenIndices = mutableSetOf<Int>()  // Track tokens to skip
            
            for ((tokenIndex, token) in tokens.withIndex()) {
                val surface = token.surface
                val pos1 = token.partOfSpeechLevel1
                val pos2 = token.partOfSpeechLevel2
                val baseForm = token.baseForm ?: surface
                
                // Debug specific tokens
                if (surface == "„Åæ„Åô" || surface == "ËÄÉ„Åà" || surface == "„Åì„ÅÆ" || surface == "„Åß" ||
                    surface == "ËâØ" || surface == "„Åï" || surface == "„Åù„ÅÜ" || surface == "Ë™∞" ||
                    surface == "„ÇÇ" || surface == "„ÅØ" || surface == "„Çâ" || surface == "„Åß„ÇÇ" || surface == "Ë™≠„ÇÅ" ||
                    surface == "Êõ∏„Åë" || surface == "„Å∞" || surface == "Ê∞ó" || surface == "‰ªò„Åë" || 
                    surface == "„Çà„Åã„Å£" || surface == "„Åü") {
                    Log.d("TokenFilter", "Processing token: '$surface' (${pos1},${pos2}) - particles check: ${particles.contains(surface)}")
                }
                
                // Find position in processed text, looking for exact match at expected position
                val tokenStartInProcessed = findTokenPosition(processedText, surface, currentPosition)
                
                // Debug „Åß tokens and preceding context
                if (surface == "„Åß") {
                    val prevText = if (tokenStartInProcessed > 0) processedText.substring(Math.max(0, tokenStartInProcessed - 5), tokenStartInProcessed) else ""
                    val nextText = if (tokenStartInProcessed >= 0 && tokenStartInProcessed + surface.length < processedText.length) 
                        processedText.substring(tokenStartInProcessed + surface.length, Math.min(processedText.length, tokenStartInProcessed + surface.length + 5)) 
                        else ""
                    Log.d("TokenPosition", "„Åß token at position $tokenStartInProcessed: [...$prevText] „Åß [$nextText...], POS: $pos1,$pos2")
                    if (prevText.contains("Ë™≠„ÇÅ")) {
                        Log.d("TokenPosition", "„Åß token follows Ë™≠„ÇÅ - index $tokenIndex, next token: ${if (tokenIndex + 1 < tokens.size) tokens[tokenIndex + 1].surface + " (${tokens[tokenIndex + 1].partOfSpeechLevel1})" else "N/A"}")
                    }
                }
                
                // Debug „Åß„ÇÇ tokens
                if (surface == "„Åß„ÇÇ") {
                    val prevText = if (tokenStartInProcessed > 0) processedText.substring(Math.max(0, tokenStartInProcessed - 5), tokenStartInProcessed) else ""
                    val nextText = if (tokenStartInProcessed >= 0 && tokenStartInProcessed + surface.length < processedText.length) 
                        processedText.substring(tokenStartInProcessed + surface.length, Math.min(processedText.length, tokenStartInProcessed + surface.length + 5)) 
                        else ""
                    Log.d("TokenPosition", "„Åß„ÇÇ token at position $tokenStartInProcessed: [...$prevText] „Åß„ÇÇ [$nextText...], POS: $pos1,$pos2")
                }
                
                // Debug Ë™≠„ÇÅ tokens
                if (surface == "Ë™≠„ÇÅ") {
                    val prevText = if (tokenStartInProcessed > 0) processedText.substring(Math.max(0, tokenStartInProcessed - 5), tokenStartInProcessed) else ""
                    val nextText = if (tokenStartInProcessed >= 0 && tokenStartInProcessed + surface.length < processedText.length) 
                        processedText.substring(tokenStartInProcessed + surface.length, Math.min(processedText.length, tokenStartInProcessed + surface.length + 5)) 
                        else ""
                    Log.d("TokenPosition", "Ë™≠„ÇÅ token at position $tokenStartInProcessed: [...$prevText] Ë™≠„ÇÅ [$nextText...], POS: $pos1,$pos2")
                    Log.d("TokenPosition", "Ë™≠„ÇÅ token index $tokenIndex, next token: ${if (tokenIndex + 1 < tokens.size) tokens[tokenIndex + 1].surface + " (${tokens[tokenIndex + 1].partOfSpeechLevel1})" else "N/A"}")
                }
                
                if (tokenStartInProcessed == -1) {
                    // Debug logging for position mapping issues
                    if (surface.contains("Âêç‰ªò„Åë") || surface == "„Åü") {
                        Log.w("PositionMap", "Failed to find '$surface' in processed text after position $currentPosition")
                    }
                    continue
                }
                
                // Map the processed text position back to original text position
                val tokenStart = mapProcessedPositionToOriginal(text, processedText, tokenStartInProcessed, surface)
                if (tokenStart == -1) {
                    currentPosition = tokenStartInProcessed + surface.length
                    continue
                }
                val tokenEnd = tokenStart + surface.length
                
                // Debug logging for problematic tokens
                if (surface.contains("Âêç‰ªò„Åë") || (surface == "„Åü" && processedText.contains("Âêç‰ªò„Åë"))) {
                    Log.d("PositionMap", "Token '$surface' mapped: processed=$tokenStartInProcessed, original=$tokenStart-$tokenEnd")
                }
                
                // Update current position for next search (in processed text)
                currentPosition = tokenStartInProcessed + surface.length
                
                // Skip punctuation and symbols
                if (pos1 == "Ë®òÂè∑" || surface.all { it.isWhitespace() }) {
                    continue
                }
                
                // Skip numbers and numeric expressions
                if (surface.all { it.isDigit() || it == '.' || it == ',' } || pos1 == "ÂêçË©û" && pos2 == "Êï∞") {
                    continue
                }
                
                // Skip single hyphens, dashes, and other connecting symbols
                if (surface in setOf("-", "Ôºç", "‚Äî", "‚Äì", "_", "/", "\\", "|")) {
                    continue
                }
                
                // Skip „Å™ (adjectival particle), but keep it if it follows „Çà„ÅÜ to form „Çà„ÅÜ„Å™
                if (surface == "„Å™") {
                    // Check if the previous token was „Çà„ÅÜ to form „Çà„ÅÜ„Å™
                    val shouldKeepForYouna = results.isNotEmpty() && 
                                           results.last().word == "„Çà„ÅÜ" &&
                                           results.last().endPosition == tokenStart
                    if (!shouldKeepForYouna) {
                        continue
                    }
                }
                
                // Skip particles unless they're part of compound words
                // Special handling for particles that are often part of compounds
                val shouldSkipParticle = if (pos1 == "Âä©Ë©û") {
                    when (surface) {
                        "„Çâ", "„ÅØ", "„ÇÇ", "„Åß" -> {
                            // These particles need special handling - check if part of compound
                            val isPartOfCompound = checkIfPartOfCompound(surface, tokens, tokenIndex, pos1)
                            // Debug logging for „Çâ particle specifically
                            if (surface == "„Çâ") {
                                Log.d("ParticleFilter", "Particle „Çâ: isPartOfCompound=$isPartOfCompound, willSkip=${!isPartOfCompound}")
                                if (tokenIndex > 0) {
                                    val prevToken = tokens[tokenIndex - 1]
                                    Log.d("ParticleFilter", "  Previous token: '${prevToken.surface}' baseForm='${prevToken.baseForm}'")
                                }
                            }
                            !isPartOfCompound
                        }
                        "„Åï" -> {
                            // Keep „Åï for adjective patterns like ËâØ„Åï„Åù„ÅÜ
                            false
                        }
                        in particles -> {
                            // Check if other particles are part of a compound
                            !checkIfPartOfCompound(surface, tokens, tokenIndex, pos1)
                        }
                        else -> {
                            // Keep unknown particles by default
                            false
                        }
                    }
                } else {
                    false
                }
                
                if (shouldSkipParticle) {
                    continue
                }
                
                // Skip „Åó and „Å†„Åó when followed by comma (grammar connectors)
                if ((surface == "„Åó" && ((pos1 == "ÂãïË©û" && token.baseForm == "„Åô„Çã") || (pos1 == "Âä©Ë©û" && pos2 == "Êé•Á∂öÂä©Ë©û"))) ||
                    (surface == "„Å†„Åó" && pos1 == "Âä©ÂãïË©û")) {
                    // Check if next token is a comma or punctuation
                    val nextTokenIndex = tokenIndex + 1
                    if (nextTokenIndex < tokens.size) {
                        val nextToken = tokens[nextTokenIndex]
                        if (nextToken.surface == "," || nextToken.surface == "„ÄÅ" ||
                            nextToken.partOfSpeechLevel1 == "Ë®òÂè∑" && 
                            (nextToken.surface == "," || nextToken.surface == "„ÄÅ")) {
                            Log.d("ParticleFilter", "Skipping $surface followed by comma (grammar connector): pos=$pos1,$pos2")
                            continue
                        }
                    }
                }
                
                // Skip „Åß„ÇÇ when it's tokenized as a single particle (Âä©Ë©û,ÂâØÂä©Ë©û)
                // BUT keep it if preceded by certain words like Ë™∞, ÁßÅ, etc. that form meaningful compounds
                if (surface == "„Åß„ÇÇ" && pos1 == "Âä©Ë©û" && pos2 == "ÂâØÂä©Ë©û") {
                    // Check if preceded by a word that should group with „Åß„ÇÇ
                    val shouldKeepForGrouping = tokenIndex > 0 && tokens[tokenIndex - 1].surface in setOf("Ë™∞", "ÁßÅ", "ÂΩº", "ÂΩºÂ•≥", "„ÅÇ„Å™„Åü")
                    if (!shouldKeepForGrouping) {
                        Log.d("ParticleFilter", "Skipping „Åß„ÇÇ particle (Âä©Ë©û,ÂâØÂä©Ë©û) to prevent incorrect highlighting")
                        continue
                    } else {
                        Log.d("ParticleFilter", "Keeping „Åß„ÇÇ particle for grouping with ${tokens[tokenIndex - 1].surface}")
                    }
                }
                
                // Skip demonstrative determiners („Åì„ÅÆ, „Åù„ÅÆ, „ÅÇ„ÅÆ, „Å©„ÅÆ)
                // Skip „ÅÇ„ÅÆ as it should be treated like a particle
                if (pos1 == "ÈÄ£‰ΩìË©û" && surface == "„ÅÇ„ÅÆ") {
                    continue
                }
                
                // Skip auxiliary verbs that are just conjugation helpers (but keep „Åü for past tense grouping)
                // Don't skip „Åß/„Å†/„Åß„Åô if they're part of compound expressions
                val isAuxiliaryPartOfCompound = checkIfAuxiliaryIsPartOfCompound(surface, tokens, tokenIndex, pos1)
                if (pos1 == "Âä©ÂãïË©û" && surface in setOf("„Å†", "„Åß„Åô") && !isAuxiliaryPartOfCompound) {
                    continue
                }
                // Special handling for auxiliary „Åß - keep it for compounds but skip „Åß+„ÇÇ patterns
                if (pos1 == "Âä©ÂãïË©û" && surface == "„Åß") {
                    // Check if followed by „ÇÇ - if so, skip this „Åß to avoid creating "Ë™≠„ÇÅ„Åß" 
                    // The „Åß„ÇÇ should be handled as a single token or the grouping will handle it
                    if (tokenIndex + 1 < tokens.size && tokens[tokenIndex + 1].surface == "„ÇÇ") {
                        Log.d("ParticleFilter", "Skipping auxiliary „Åß followed by „ÇÇ to prevent incorrect word boundaries")
                        // Mark the next token („ÇÇ) to be skipped as well
                        skippedTokenIndices.add(tokenIndex + 1)
                        continue
                    }
                    
                    if (!isAuxiliaryPartOfCompound) {
                        // Still check if it should be kept for other patterns
                        val shouldKeepDe = tokenIndex + 1 < tokens.size && 
                                          (tokens[tokenIndex + 1].surface == "„ÅØ" || 
                                           tokens[tokenIndex + 1].surface == "„Å™„ÅÑ")
                        if (!shouldKeepDe) {
                            continue
                        }
                    }
                }
                
                // Skip tokens that were marked to be skipped by previous logic
                if (skippedTokenIndices.contains(tokenIndex)) {
                    Log.d("ParticleFilter", "Skipping token $surface (marked by previous filtering logic)")
                    continue
                }
                
                // Skip non-Japanese text (like English letters or symbols)
                if (!surface.any { JAPANESE_CHAR.matches(it.toString()) }) {
                    continue
                }
                
                // Don't skip tokens that are part of compound expressions
                // Keep „Åï (suffix) for adjective patterns like ËâØ„Åï„Åù„ÅÜ
                if (surface == "„Åï" && pos1 == "Êé•Â∞æ") {
                    // Keep this for adjective patterns
                }
                // Keep „Åù„ÅÜ for seeming/appearance patterns
                else if (surface == "„Åù„ÅÜ" && (pos1 == "ÂêçË©û" || pos1 == "ÂΩ¢ÂÆπË©û")) {
                    // Keep this for „Åù„ÅÜ patterns
                }
                
                // Keep surface form for grouping, don't convert to base form yet
                val wordToAdd = surface
                
                // Debug logging for specific problematic words  
                if (surface in setOf("„Åó", "Á©ç„Åø", "„Åæ„Åó„Åü", "„Åæ„Åó", "„Åü", "Ë¶ã", "„Çâ„Çå", "„Åæ„Åõ", "„Çì", "„Çì„Åß", "„Åü„Åè", "„Å™„ÅÑ", "„Å™„Åã„Å£", "„Åó„Åü„Çâ", "„Çâ")) {
                    Log.d("KuromojiDebug", "Processing token: '$surface' pos='$pos1,$pos2' baseForm='$baseForm'")
                }
                
                // Special handling for „Åó„Åü„Çâ conditional - split it into „Åó„Åü + „Çâ tokens
                // Kuromoji sometimes tags „Åó„Åü„Çâ as Êé•Á∂öË©û (conjunction) instead of ÂãïË©û (verb)
                if (surface == "„Åó„Åü„Çâ" && (pos1 == "ÂãïË©û" || pos1 == "Êé•Á∂öË©û")) {
                    Log.d("KuromojiDebug", "Splitting „Åó„Åü„Çâ into „Åó„Åü + „Çâ tokens")
                    
                    // Create WordPosition for „Åó„Åü with original token for base form info
                    results.add(WordPosition("„Åó„Åü", tokenStart, tokenStart + 2, sequenceId, token, "„Åô„Çã"))
                    sequenceId++
                    
                    // Create WordPosition for „Çâ (no base form needed for particles)
                    results.add(WordPosition("„Çâ", tokenStart + 2, tokenEnd, sequenceId, null, null))
                    sequenceId++
                } else {
                    // Add the word with its position, unique sequence ID, and original Kuromoji token
                    results.add(WordPosition(wordToAdd, tokenStart, tokenEnd, sequenceId, token))
                    sequenceId++
                }
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "Kuromoji tokenization failed: ${e.message}", e)
            // Fallback to simple extraction if Kuromoji fails
            return extractJapaneseWordsWithPositions(text)
        }
        
        // Use the simplified Kuromoji-only approach (most reliable)
        val finalResults = groupConsecutiveVerbTokens(results, processedText)
        
        Log.d("KuromojiGrouping", "Kuromoji-only grouping: ${results.size} tokens ‚Üí ${finalResults.size} tokens")
        
        return finalResults
    }
    
    /**
     * Group adjacent tokens that form logical units (like verb conjugations)
     * This prevents fragmenting words like "Âêä„Å£„Å¶„ÅÑ„Çã" into separate highlight regions
     */
    private fun groupRelatedTokens(tokens: List<WordPosition>, text: String): List<WordPosition> {
        if (tokens.isEmpty()) return tokens
        
        // Debug: Check if we have the problematic tokens
        val hasProblematicTokens = tokens.any { it.word == "ËÄÉ„Åà" || it.word == "ÊÄù„ÅÑ" || it.word.contains("Âêç‰ªò„Åë") }
        if (hasProblematicTokens) {
            Log.d("TokenGroup", "Found tokens to debug: ${tokens.map { "${it.word}(${it.startPosition}-${it.endPosition})" }}")
            
            // Check what comes after ËÄÉ„Åà in the text
            val kangaeToken = tokens.find { it.word == "ËÄÉ„Åà" }
            if (kangaeToken != null) {
                val endPos = kangaeToken.endPosition
                val nextChars = if (endPos + 5 <= text.length) text.substring(endPos, endPos + 5) else text.substring(endPos)
                Log.d("TokenGroup", "Text after ËÄÉ„Åà (pos ${endPos}): '$nextChars'")
            }
            
            // Debug Âêç‰ªò„Åë tokens specifically
            val nazukeTokens = tokens.filter { it.word.contains("Âêç‰ªò„Åë") }
            nazukeTokens.forEach { token ->
                Log.d("TokenGroup", "DEBUG Âêç‰ªò„Åë token: '${token.word}' at ${token.startPosition}-${token.endPosition}")
            }
        }
        
        // Token grouping process
        
        val grouped = mutableListOf<WordPosition>()
        var i = 0
        
        while (i < tokens.size) {
            val currentToken = tokens[i]
            val currentKuromojiToken = currentToken.kuromojiToken
            if (currentKuromojiToken == null) {
                grouped.add(currentToken)
                i++
                continue
            }
            
            val groupCandidates = mutableListOf(Pair(currentToken, currentKuromojiToken))
            var j = i + 1
            
            // Look ahead for tokens that should be grouped with current token
            while (j < tokens.size) {
                val nextToken = tokens[j]
                val nextKuromojiToken = nextToken.kuromojiToken ?: break
                
                // Check if tokens are adjacent
                val isAdjacent = nextToken.startPosition <= groupCandidates.last().first.endPosition + 2
                
                if (!isAdjacent) break
                
                // Check if current group + next token should be grouped
                val shouldGroup = shouldGroupTokensNew(
                    groupCandidates.last().second, 
                    nextKuromojiToken,
                    groupCandidates.last().first,
                    nextToken
                )
                
                if (shouldGroup) {
                    groupCandidates.add(Pair(nextToken, nextKuromojiToken))
                    j++
                } else {
                    break
                }
            }
            
            // Handle special three-token pattern: verb „ÇøÊé•Á∂ö + „Å¶ + auxiliary (like Âêä„Å£-„Å¶-„ÅÑ„Çã)
            if (groupCandidates.size == 2 && j < tokens.size) {
                val thirdToken = tokens[j]
                val thirdKuromojiToken = thirdToken.kuromojiToken
                
                // Check if we have: verb „ÇøÊé•Á∂ö + „Å¶ + auxiliary verb
                if (groupCandidates.size == 2 && thirdKuromojiToken != null &&
                    groupCandidates[0].second.partOfSpeechLevel1 == "ÂãïË©û" &&
                    groupCandidates[0].second.conjugationForm == "ÈÄ£Áî®„ÇøÊé•Á∂ö" &&
                    groupCandidates[1].first.word == "„Å¶" &&
                    thirdToken.startPosition <= groupCandidates[1].first.endPosition + 2 &&
                    thirdKuromojiToken.partOfSpeechLevel1 == "ÂãïË©û" &&
                    thirdKuromojiToken.partOfSpeechLevel2 == "ÈùûËá™Á´ã") {
                    
                    groupCandidates.add(Pair(thirdToken, thirdKuromojiToken))
                    j++
                    Log.d(TAG, "Added third token for verb+„Å¶+auxiliary pattern: ${thirdToken.word}")
                }
                // Pattern B: verb ÈÄ£Áî®ÂΩ¢ + „Å¶ + „ÅÑ (continuous form like ËÄÉ„Åà-„Å¶-„ÅÑ)  
                else if (groupCandidates.size == 2 && thirdKuromojiToken != null &&
                    groupCandidates[0].second.partOfSpeechLevel1 == "ÂãïË©û" &&
                    groupCandidates[0].second.partOfSpeechLevel2 == "Ëá™Á´ã" &&
                    groupCandidates[0].second.conjugationForm == "ÈÄ£Áî®ÂΩ¢" &&
                    groupCandidates[1].first.word == "„Å¶" &&
                    thirdToken.word == "„ÅÑ" &&
                    thirdToken.startPosition <= groupCandidates[1].first.endPosition + 2 &&
                    thirdKuromojiToken.partOfSpeechLevel1 == "ÂãïË©û" &&
                    thirdKuromojiToken.partOfSpeechLevel2 == "ÈùûËá™Á´ã") {
                    
                    Log.d("TokenGroup", "Three-token pattern B: ${groupCandidates[0].first.word}+${groupCandidates[1].first.word}+${thirdToken.word} (ÈÄ£Áî®ÂΩ¢+„Å¶+„ÅÑ)")
                    groupCandidates.add(Pair(thirdToken, thirdKuromojiToken))
                    j++
                }
                // Pattern C: verb ÈÄ£Áî®ÂΩ¢ + „Åæ„Åó + „Åü (polite past form like Á©ç„Åø-„Åæ„Åó-„Åü)
                else if (groupCandidates.size == 2 && thirdKuromojiToken != null &&
                    groupCandidates[0].second.partOfSpeechLevel1 == "ÂãïË©û" &&
                    groupCandidates[0].second.partOfSpeechLevel2 == "Ëá™Á´ã" &&
                    groupCandidates[0].second.conjugationForm == "ÈÄ£Áî®ÂΩ¢" &&
                    groupCandidates[1].first.word == "„Åæ„Åó" &&
                    groupCandidates[1].second.partOfSpeechLevel1 == "Âä©ÂãïË©û" &&
                    thirdToken.word == "„Åü" &&
                    thirdToken.startPosition <= groupCandidates[1].first.endPosition + 2 &&
                    thirdKuromojiToken.partOfSpeechLevel1 == "Âä©ÂãïË©û") {
                    
                    Log.d("TokenGroup", "Three-token pattern C: ${groupCandidates[0].first.word}+${groupCandidates[1].first.word}+${thirdToken.word} (ÈÄ£Áî®ÂΩ¢+„Åæ„Åó+„Åü)")
                    groupCandidates.add(Pair(thirdToken, thirdKuromojiToken))
                    j++
                }
            }
            
            // Create grouped token
            if (groupCandidates.size > 1) {
                val firstToken = groupCandidates.first().first
                val lastToken = groupCandidates.last().first
                val groupedWord = groupCandidates.joinToString("") { it.first.word }
                
                // Group the tokens into a single word
                
                // Debug logging for merged tokens containing our problematic cases
                if (groupCandidates.any { it.first.word == "ËÄÉ„Åà" || it.first.word == "ÊÄù„ÅÑ" }) {
                    val tokenWords = groupCandidates.map { it.first.word }.joinToString("+")
                    Log.d("TokenGroup", "Created merged token: $tokenWords ‚Üí $groupedWord")
                }
                
                grouped.add(WordPosition(
                    word = groupedWord,
                    startPosition = firstToken.startPosition,
                    endPosition = lastToken.endPosition,
                    sequenceId = firstToken.sequenceId, // Use first token's sequence ID
                    kuromojiToken = firstToken.kuromojiToken // Preserve main verb's token for further grouping
                ))
                
                i = j // Skip all grouped tokens
            } else {
                // Single token, add as-is
                // Debug for ungrouped problematic tokens
                if (currentToken.word == "ËÄÉ„Åà" || currentToken.word == "ÊÄù„ÅÑ" || currentToken.word == "ËÄÉ„Åà„Å¶„ÅÑ") {
                    Log.d("TokenGroup", "Token ${currentToken.word} was NOT grouped")
                }
                grouped.add(currentToken)
                i++
            }
        }
        
        return grouped
    }
    
    /**
     * SIMPLIFIED APPROACH: Group consecutive verb + auxiliary tokens based on Kuromoji's base forms
     * Much simpler than rule-based approach - just stitch verb + following auxiliaries together
     */
    private fun groupConsecutiveVerbTokens(tokens: List<WordPosition>, text: String): List<WordPosition> {
        if (tokens.isEmpty()) return tokens
        
        val grouped = mutableListOf<WordPosition>()
        var i = 0
        
        while (i < tokens.size) {
            val currentToken = tokens[i]
            val currentKuromojiToken = currentToken.kuromojiToken
            
            // Debug ALL „Åß tokens
            if (currentToken.word == "„Åß") {
                val nextWord = if (i + 1 < tokens.size) tokens[i + 1].word else "END"
                val nextNextWord = if (i + 2 < tokens.size) tokens[i + 2].word else "END"
                Log.d("SimplifiedGrouping", "üîç Processing „Åß token at position $i: „Åß ‚Üí $nextWord ‚Üí $nextNextWord (positions: ${currentToken.startPosition}-${currentToken.endPosition})")
            }
            
            if (currentKuromojiToken == null) {
                grouped.add(currentToken)
                i++
                continue
            }
            
            // Check if this is a main verb (ÂãïË©û/Ëá™Á´ã) or any verb that could start a sequence
            val pos1_1 = currentKuromojiToken.partOfSpeechLevel1
            val pos1_2 = currentKuromojiToken.partOfSpeechLevel2
            
            // Check if this is a demonstrative pronoun that should be grouped with ÊôÇ (except „ÅÇ„ÅÆ)
            // „Åù„ÅÆÊôÇ, „Åì„ÅÆÊôÇ, „Å©„ÅÆÊôÇ are dictionary compounds, but „ÅÇ„ÅÆÊôÇ should stay separate
            val isDemonstrativeWithJi = (pos1_1 == "ÈÄ£‰ΩìË©û" && currentToken.word in setOf("„Åù„ÅÆ", "„Åì„ÅÆ", "„Å©„ÅÆ")) &&
                                        i + 1 < tokens.size &&
                                        tokens[i + 1].word == "ÊôÇ" &&
                                        tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂêçË©û" &&
                                        tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is „Å†„Çç or „Åæ„Åó„Çá that should be grouped with following „ÅÜ 
            val isVolitionalPart = ((currentToken.word == "„Å†„Çç" && pos1_1 == "Âä©ÂãïË©û") ||
                                   (currentToken.word == "„Åæ„Åó„Çá" && pos1_1 == "Âä©ÂãïË©û")) &&
                                  i + 1 < tokens.size &&
                                  tokens[i + 1].word == "„ÅÜ" &&
                                  tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©ÂãïË©û" &&
                                  tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is conditional form (verb + „Å∞)
            val isConditional = pos1_1 == "ÂãïË©û" && pos1_2 == "Ëá™Á´ã" &&
                               i + 1 < tokens.size &&
                               tokens[i + 1].word == "„Å∞" &&
                               tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                               tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is past tense i-adjective (stem + „Åü)
            val isAdjectivePast = pos1_1 == "ÂΩ¢ÂÆπË©û" && pos1_2 == "Ëá™Á´ã" &&
                                 currentToken.word.endsWith("„Åã„Å£") &&
                                 i + 1 < tokens.size &&
                                 tokens[i + 1].word == "„Åü" &&
                                 tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©ÂãïË©û" &&
                                 tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is Ê∞ó„Çí„Å§„Åë compound expression (Ê∞ó + „Çí + „Å§„Åë)
            val isKiWoTsuke = currentToken.word == "Ê∞ó" && pos1_1 == "ÂêçË©û" &&
                             i + 2 < tokens.size &&
                             tokens[i + 1].word == "„Çí" &&
                             tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                             tokens[i + 2].word == "„Å§„Åë" &&
                             tokens[i + 2].kuromojiToken?.partOfSpeechLevel1 == "ÂãïË©û" &&
                             tokens[i + 1].startPosition <= currentToken.endPosition + 2 &&
                             tokens[i + 2].startPosition <= tokens[i + 1].endPosition + 2
            
            // Check if this is ÊúùÊó©„Åè compound expression (Êúù + Êó©„Åè)
            val isAsaHayaku = currentToken.word == "Êúù" && pos1_1 == "ÂêçË©û" &&
                             i + 1 < tokens.size &&
                             tokens[i + 1].word == "Êó©„Åè" &&
                             (tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂâØË©û" || 
                              tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂΩ¢ÂÆπË©û") &&
                             tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            
            // Check if this is „ÅÜ„Åæ„Åè„ÅÑ„Åç„Åù„ÅÜ compound expression („ÅÜ„Åæ„Åè + „ÅÑ„Åç + „Åù„ÅÜ)
            val isUmakuIkiSou = currentToken.word == "„ÅÜ„Åæ„Åè" && (pos1_1 == "ÂâØË©û" || pos1_1 == "ÂΩ¢ÂÆπË©û") &&
                               i + 2 < tokens.size &&
                               tokens[i + 1].word == "„ÅÑ„Åç" &&
                               tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂãïË©û" &&
                               tokens[i + 2].word == "„Åù„ÅÜ" &&
                               (tokens[i + 2].kuromojiToken?.partOfSpeechLevel1 == "ÂêçË©û" || tokens[i + 2].kuromojiToken?.partOfSpeechLevel1 == "Âä©ÂãïË©û") &&
                               tokens[i + 1].startPosition <= currentToken.endPosition + 2 &&
                               tokens[i + 2].startPosition <= tokens[i + 1].endPosition + 2
            
            // Debug logging for „ÅÜ„Åæ„Åè„ÅÑ„Åç„Åù„ÅÜ detection
            if (currentToken.word == "„ÅÜ„Åæ„Åè") {
                Log.d("SimplifiedGrouping", "Found „ÅÜ„Åæ„Åè token at position $i: pos='$pos1_1', hasNext2=${i + 2 < tokens.size}")
                if (i + 1 < tokens.size && i + 2 < tokens.size) {
                    val nextToken1 = tokens[i + 1]
                    val nextToken2 = tokens[i + 2]
                    Log.d("SimplifiedGrouping", "  Next token1: '${nextToken1.word}' pos='${nextToken1.kuromojiToken?.partOfSpeechLevel1}'")
                    Log.d("SimplifiedGrouping", "  Next token2: '${nextToken2.word}' pos='${nextToken2.kuromojiToken?.partOfSpeechLevel1}'")
                    Log.d("SimplifiedGrouping", "  Expected: „ÅÑ„Åç (ÂãïË©û) + „Åù„ÅÜ (ÂêçË©û|Âä©ÂãïË©û)")
                    Log.d("SimplifiedGrouping", "  Actual: ${nextToken1.word} (${nextToken1.kuromojiToken?.partOfSpeechLevel1}) + ${nextToken2.word} (${nextToken2.kuromojiToken?.partOfSpeechLevel1})")
                    Log.d("SimplifiedGrouping", "  Position checks: ${nextToken1.startPosition} <= ${currentToken.endPosition + 2}, ${nextToken2.startPosition} <= ${nextToken1.endPosition + 2}")
                    Log.d("SimplifiedGrouping", "  isUmakuIkiSou check result: $isUmakuIkiSou")
                }
            }
            
            // Check if this is Ê∞ó„Çí„Å§„Åë„Çà„ÅÜ compound expression (Ê∞ó + „Å§„Åë„Çà + „ÅÜ)
            val isKiWoTsukeyou = currentToken.word == "Ê∞ó" && pos1_1 == "ÂêçË©û" &&
                                i + 2 < tokens.size &&
                                tokens[i + 1].word == "„Å§„Åë„Çà" &&
                                tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂãïË©û" &&
                                tokens[i + 2].word == "„ÅÜ" &&
                                tokens[i + 2].kuromojiToken?.partOfSpeechLevel1 == "Âä©ÂãïË©û" &&
                                tokens[i + 1].startPosition <= currentToken.endPosition + 2 &&
                                tokens[i + 2].startPosition <= tokens[i + 1].endPosition + 2
            
            // Debug logging for Ê∞ó„Çí„Å§„Åë„Çà„ÅÜ detection
            if (currentToken.word == "Ê∞ó") {
                Log.d("SimplifiedGrouping", "Found Ê∞ó token at position $i: pos='$pos1_1', hasNext2=${i + 2 < tokens.size}")
                // Show available tokens regardless of count
                Log.d("SimplifiedGrouping", "  Available tokens after Ê∞ó:")
                for (j in 1..2) {
                    if (i + j < tokens.size) {
                        val nextToken = tokens[i + j]
                        Log.d("SimplifiedGrouping", "    Token $j: '${nextToken.word}' pos='${nextToken.kuromojiToken?.partOfSpeechLevel1}'")
                    } else {
                        Log.d("SimplifiedGrouping", "    Token $j: [NO TOKEN - end of list]")
                    }
                }
                if (i + 2 < tokens.size) {
                    val nextToken1 = tokens[i + 1]
                    val nextToken2 = tokens[i + 2] 
                    Log.d("SimplifiedGrouping", "  Expected: „Å§„Åë„Çà (ÂãïË©û) + „ÅÜ (Âä©ÂãïË©û)")
                    Log.d("SimplifiedGrouping", "  Actual: ${nextToken1.word} (${nextToken1.kuromojiToken?.partOfSpeechLevel1}) + ${nextToken2.word} (${nextToken2.kuromojiToken?.partOfSpeechLevel1})")
                    Log.d("SimplifiedGrouping", "  Position checks: ${nextToken1.startPosition} <= ${currentToken.endPosition + 2}, ${nextToken2.startPosition} <= ${nextToken1.endPosition + 2}")
                    Log.d("SimplifiedGrouping", "  isKiWoTsukeyou check result: $isKiWoTsukeyou")
                }
            }
            
            // Check if this is an adjective that should be grouped with following „Å¶ to form „Å¶-form
            val isAdjectiveWithTe = (pos1_1 == "ÂΩ¢ÂÆπË©û" && pos1_2 == "Ëá™Á´ã") &&
                                   i + 1 < tokens.size &&
                                   tokens[i + 1].word == "„Å¶" &&
                                   tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                                   tokens[i + 1].kuromojiToken?.partOfSpeechLevel2 == "Êé•Á∂öÂä©Ë©û" &&
                                   tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Allow main verbs OR verbs with „Åô„Çã base form (covers conjugated „Åô„Çã forms like „Åï)
            val isVerbStart = (pos1_1 == "ÂãïË©û" && pos1_2 == "Ëá™Á´ã") || 
                             (pos1_1 == "ÂãïË©û" && currentKuromojiToken.baseForm == "„Åô„Çã")
            
            // Check if this is a noun that should be grouped with ËÄÖ (person/agent suffix)
            val isNounForAgentSuffix = (pos1_1 == "ÂêçË©û" && (pos1_2 == "‰∏ÄËà¨" || pos1_2 == "„ÇµÂ§âÊé•Á∂ö")) && 
                                      i + 1 < tokens.size && 
                                      tokens[i + 1].word == "ËÄÖ" &&
                                      tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is a noun that should be grouped with noun suffix (like ÂÖâ, ÊÄß, Âåñ, etc.)
            // But exclude date components (Êúà+Êó•) which should stay separate  
            val isNounForSuffix = (pos1_1 == "ÂêçË©û" && (pos1_2 == "‰∏ÄËà¨" || pos1_2 == "„ÇµÂ§âÊé•Á∂ö" || pos1_2 == "ÂâØË©ûÂèØËÉΩ")) && 
                                  i + 1 < tokens.size && 
                                  tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂêçË©û" &&
                                  tokens[i + 1].kuromojiToken?.partOfSpeechLevel2 == "Êé•Â∞æ" &&
                                  tokens[i + 1].startPosition <= currentToken.endPosition + 2 &&
                                  // Don't group Êúà+Êó• (month+day) as they're separate date components
                                  !(currentToken.word == "Êúà" && tokens[i + 1].word == "Êó•")
            
            // Check if this is a prefix that should be grouped with following noun
            val isPrefixForNoun = (pos1_1 == "Êé•È†≠Ë©û" && pos1_2 == "ÂêçË©ûÊé•Á∂ö") &&
                                  i + 1 < tokens.size &&
                                  tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂêçË©û" &&
                                  tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is „Çà„ÅÜ that should be grouped with following „Å™ to form „Çà„ÅÜ„Å™
            val isYouNa = (currentToken.word == "„Çà„ÅÜ" && pos1_1 == "ÂêçË©û") &&
                          i + 1 < tokens.size &&
                          tokens[i + 1].word == "„Å™" &&
                          tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is „Çà„ÅÜ that should be grouped with following „Å´ to form „Çà„ÅÜ„Å´
            val isYouNi = (currentToken.word == "„Çà„ÅÜ" && pos1_1 == "ÂêçË©û") &&
                          i + 1 < tokens.size &&
                          tokens[i + 1].word == "„Å´" &&
                          tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                          tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is „Å® that should be grouped with following „ÅÑ„ÅÜ to form „Å®„ÅÑ„ÅÜ
            val isToIu = (currentToken.word == "„Å®" && pos1_1 == "Âä©Ë©û") &&
                         i + 1 < tokens.size &&
                         tokens[i + 1].word == "„ÅÑ„ÅÜ" &&
                         tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂãïË©û" &&
                         tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is „Åß that should be grouped with „ÅØ+„Å™„ÅÑ to form „Åß„ÅØ„Å™„ÅÑ
            // Note: „Åß can be either auxiliary verb or particle
            val isDeWaNai = currentToken.word == "„Åß" &&
                            i + 2 < tokens.size &&
                            tokens[i + 1].word == "„ÅØ" &&
                            tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                            tokens[i + 2].word == "„Å™„ÅÑ" &&
                            (tokens[i + 2].kuromojiToken?.partOfSpeechLevel1 == "Âä©ÂãïË©û" || tokens[i + 2].kuromojiToken?.partOfSpeechLevel1 == "ÂΩ¢ÂÆπË©û") &&
                            tokens[i + 1].startPosition <= currentToken.endPosition + 2 &&
                            tokens[i + 2].startPosition <= tokens[i + 1].endPosition + 2
            
            // Check if this is „Åß that should be grouped with „ÇÇ to form „Åß„ÇÇ
            // Note: „Åß can be either auxiliary verb or particle
            val isDeMo = currentToken.word == "„Åß" &&
                         i + 1 < tokens.size &&
                         tokens[i + 1].word == "„ÇÇ" &&
                         tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                         tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is „Åß that should be grouped with „ÇÇ+„Å™„ÅÑ to form „Åß„ÇÇ„Å™„ÅÑ
            // Note: „Åß can be either auxiliary verb or particle  
            val isDeMoNai = currentToken.word == "„Åß" &&
                            i + 2 < tokens.size &&
                            tokens[i + 1].word == "„ÇÇ" &&
                            tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                            tokens[i + 2].word == "„Å™„ÅÑ" &&
                            (tokens[i + 2].kuromojiToken?.partOfSpeechLevel1 == "Âä©ÂãïË©û" || tokens[i + 2].kuromojiToken?.partOfSpeechLevel1 == "ÂΩ¢ÂÆπË©û") &&
                            tokens[i + 1].startPosition <= currentToken.endPosition + 2 &&
                            tokens[i + 2].startPosition <= tokens[i + 1].endPosition + 2
            
            if (currentToken.word == "„Åß" && i + 1 < tokens.size && tokens[i + 1].word == "„ÇÇ") {
                Log.d("SimplifiedGrouping", "Found „Åß + „ÇÇ pattern: isDeMo=$isDeMo, isDeMoNai=$isDeMoNai, nextToken=${tokens[i+1].word}, nextPOS=${tokens[i + 1].kuromojiToken?.partOfSpeechLevel1}")
            }
            
            if (currentToken.word == "„Åß" && i + 2 < tokens.size) {
                Log.d("SimplifiedGrouping", "Checking „Åß patterns: next=${tokens[i+1].word}, next2=${if (i+2 < tokens.size) tokens[i+2].word else "N/A"}")
            }
            
            // Check if this is a verb that should be grouped with „Åü„Çä/„Å†„Çä
            // „Åó„Åü„Çä pattern: „Åó + „Åü„Çä
            val isShitari = (currentToken.word == "„Åó" && pos1_1 == "ÂãïË©û" && currentKuromojiToken.baseForm == "„Åô„Çã") &&
                           i + 1 < tokens.size &&
                           tokens[i + 1].word == "„Åü„Çä" &&
                           tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                           tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // General verb + „Åü„Çä/„Å†„Çä pattern
            val isTariDariPattern = (pos1_1 == "ÂãïË©û" && pos1_2 == "Ëá™Á´ã" && !isShitari) &&
                                   i + 1 < tokens.size &&
                                   (tokens[i + 1].word == "„Åü„Çä" || tokens[i + 1].word == "„Å†„Çä") &&
                                   tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                                   tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is „ÅÇ„Çå that should be grouped with following „Å∞ to form „ÅÇ„Çå„Å∞ (conditional)
            val isAreba = (currentToken.word == "„ÅÇ„Çå" && pos1_1 == "ÂãïË©û") &&
                          i + 1 < tokens.size &&
                          tokens[i + 1].word == "„Å∞" &&
                          tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                          tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is an adjective stem + „Åù„ÅÜ pattern (like ËâØ„Åï + „Åù„ÅÜ ‚Üí ËâØ„Åï„Åù„ÅÜ)
            // Also check for general noun stems that form „Åù„ÅÜ expressions
            // Note: ËâØ„Åï may be parsed as ËâØ + „Åï + „Åù„ÅÜ, so also check for „Åï + „Åù„ÅÜ
            val isAdjectiveWithSou = ((pos1_1 == "ÂêçË©û" && pos1_2 == "ÂΩ¢ÂÆπÂãïË©ûË™ûÂππ") ||
                                     (pos1_1 == "ÂêçË©û" && pos1_2 == "‰∏ÄËà¨" && currentToken.word.endsWith("„Åï")) ||
                                     (currentToken.word == "„Åï" && pos1_1 == "Êé•Â∞æ")) &&
                                    i + 1 < tokens.size &&
                                    tokens[i + 1].word == "„Åù„ÅÜ" &&
                                    (tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂêçË©û" || 
                                     tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂΩ¢ÂÆπË©û") &&
                                    tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this needs to be a three-token pattern: ËâØ + „Åï + „Åù„ÅÜ ‚Üí ËâØ„Åï„Åù„ÅÜ
            // Check for ËâØ„Åï„Åù„ÅÜ pattern - need to handle POS tags correctly
            val isThreePartAdjective = (pos1_1 == "ÂΩ¢ÂÆπË©û" && currentToken.word == "ËâØ") &&
                                      i + 2 < tokens.size &&
                                      tokens[i + 1].word == "„Åï" &&
                                      (tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂêçË©û" && 
                                       tokens[i + 1].kuromojiToken?.partOfSpeechLevel2 == "Êé•Â∞æ") &&
                                      tokens[i + 2].word == "„Åù„ÅÜ" &&
                                      (tokens[i + 2].kuromojiToken?.partOfSpeechLevel1 == "ÂêçË©û" && 
                                       tokens[i + 2].kuromojiToken?.partOfSpeechLevel2 == "Êé•Â∞æ") &&
                                      tokens[i + 1].startPosition <= currentToken.endPosition + 2 &&
                                      tokens[i + 2].startPosition <= tokens[i + 1].endPosition + 2
            
            if (currentToken.word == "ËâØ" && i + 2 < tokens.size) {
                Log.d("SimplifiedGrouping", "Checking ËâØ„Åï„Åù„ÅÜ: next=${tokens[i+1].word}(${tokens[i+1].kuromojiToken?.partOfSpeechLevel1},${tokens[i+1].kuromojiToken?.partOfSpeechLevel2}), next2=${tokens[i+2].word}(${tokens[i+2].kuromojiToken?.partOfSpeechLevel1},${tokens[i+2].kuromojiToken?.partOfSpeechLevel2})")
            }
            
            // Check if this is „Åó„Åü„Çâ conditional pattern („Åó„Åü + „Çâ)
            // Note: Kuromoji often parses this as „Åó„Åü + „Çâ rather than „Åó + „Åü„Çâ
            // Special case: when we artificially split „Åó„Åü„Çâ, the tokens may have different POS tags
            val isShitara = (currentToken.word == "„Åó„Åü" && (pos1_1 == "ÂãïË©û" || pos1_1 == "Êé•Á∂öË©û")) &&
                           i + 1 < tokens.size &&
                           tokens[i + 1].word == "„Çâ" &&
                           (tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" || tokens[i + 1].kuromojiToken == null) &&
                           tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Debug logging for „Åó„Åü„Çâ pattern
            if (currentToken.word == "„Åó„Åü" && i + 1 < tokens.size) {
                val nextToken = tokens[i + 1]
                Log.d("SimplifiedGrouping", "üîç Checking „Åó„Åü„Çâ: „Åó„Åü + ${nextToken.word}(${nextToken.kuromojiToken?.partOfSpeechLevel1}) = $isShitara")
                Log.d("SimplifiedGrouping", "  Position check: current=${currentToken.endPosition}, next=${nextToken.startPosition}, diff=${nextToken.startPosition - currentToken.endPosition}")
                Log.d("SimplifiedGrouping", "  Detailed check: pos1='${pos1_1}', nextWord='${nextToken.word}', nextPOS='${nextToken.kuromojiToken?.partOfSpeechLevel1}'")
            }
            
            // Additional debug for any „Çâ token
            if (currentToken.word == "„Çâ") {
                Log.d("SimplifiedGrouping", "Found „Çâ token at position ${currentToken.startPosition}-${currentToken.endPosition}")
                if (i > 0) {
                    val prevToken = tokens[i - 1] 
                    Log.d("SimplifiedGrouping", "  Previous token: '${prevToken.word}' pos=${prevToken.startPosition}-${prevToken.endPosition}")
                }
            }
            
            // Check if this is Ë™∞„Åß„ÇÇ pattern (Ë™∞ + „Åß + „ÇÇ)
            // Note: „Åß might not be recognized as Âä©Ë©û, check for both „Åß and „Åß„ÇÇ pattern
            val isDaredemo = (currentToken.word == "Ë™∞" && pos1_1 == "ÂêçË©û") &&
                            ((i + 2 < tokens.size &&
                              tokens[i + 1].word == "„Åß" &&
                              tokens[i + 2].word == "„ÇÇ" &&
                              tokens[i + 1].startPosition <= currentToken.endPosition + 2 &&
                              tokens[i + 2].startPosition <= tokens[i + 1].endPosition + 2) ||
                             (i + 1 < tokens.size &&
                              tokens[i + 1].word == "„Åß„ÇÇ" &&
                              tokens[i + 1].startPosition <= currentToken.endPosition + 2))
            
            if (currentToken.word == "Ë™∞" && i + 1 < tokens.size) {
                Log.d("SimplifiedGrouping", "Checking Ë™∞„Åß„ÇÇ: next=${tokens[i+1].word}, has2=${i+2 < tokens.size}, next2=${if (i+2 < tokens.size) tokens[i+2].word else "N/A"}")
            }
            
            // Check if this is „Å®„ÅØ„ÅÑ„Åà pattern („Å® + „ÅØ + „ÅÑ„Åà/Ë®Ä„Åà)
            val isToWaIe = (currentToken.word == "„Å®" && pos1_1 == "Âä©Ë©û") &&
                          i + 2 < tokens.size &&
                          tokens[i + 1].word == "„ÅØ" &&
                          tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©Ë©û" &&
                          (tokens[i + 2].word == "Ë®Ä„Åà" || tokens[i + 2].word == "„ÅÑ„Åà") &&
                          tokens[i + 2].kuromojiToken?.partOfSpeechLevel1 == "ÂãïË©û" &&
                          tokens[i + 1].startPosition <= currentToken.endPosition + 2 &&
                          tokens[i + 2].startPosition <= tokens[i + 1].endPosition + 2
            
            // Check if this is ‰ªä„Åô„Åê pattern (‰ªä + „Åô„Åê)
            val isImaSugu = (currentToken.word == "‰ªä" && (pos1_1 == "ÂêçË©û" || pos1_1 == "ÂâØË©û")) &&
                           i + 1 < tokens.size &&
                           tokens[i + 1].word == "„Åô„Åê" &&
                           (tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂâØË©û" || 
                            tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂêçË©û") &&
                           tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is „Åó„Çà„ÅÜ volitional pattern („Åó„Çà + „ÅÜ)
            val isShiyou = (currentToken.word == "„Åó„Çà" && pos1_1 == "ÂãïË©û" && currentKuromojiToken.baseForm == "„Åô„Çã") &&
                          i + 1 < tokens.size &&
                          tokens[i + 1].word == "„ÅÜ" &&
                          tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©ÂãïË©û" &&
                          tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is a general volitional „Åù„ÅÜ pattern (verb stem + „Åù„ÅÜ)
            // Like Áõ¥„Åù„ÅÜ („Å™„Åä„Åù + „ÅÜ)
            val isVolitionalSou = (pos1_1 == "ÂãïË©û" && currentToken.word.endsWith("„Åù")) &&
                                 i + 1 < tokens.size &&
                                 tokens[i + 1].word == "„ÅÜ" &&
                                 tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©ÂãïË©û" &&
                                 tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is a volitional „Çç„ÅÜ pattern (verb stem + „Çç„ÅÜ)
            // Like Ëµ∞„Çç„ÅÜ (Ëµ∞„Çç + „ÅÜ)
            val isVolitionalRou = (pos1_1 == "ÂãïË©û" && currentToken.word.endsWith("„Çç")) &&
                                 i + 1 < tokens.size &&
                                 tokens[i + 1].word == "„ÅÜ" &&
                                 tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©ÂãïË©û" &&
                                 tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is a noun that should be grouped with following „Å™„Åè (adverbial form of „Å™„ÅÑ)
            // Forms adverbial expressions like Èñ¢‰øÇ„Å™„Åè (regardless), ÂïèÈ°å„Å™„Åè (without problem)
            val isNounNaku = (pos1_1 == "ÂêçË©û" && (pos1_2 == "‰∏ÄËà¨" || pos1_2 == "„ÇµÂ§âÊé•Á∂ö" || pos1_2 == "ÂâØË©ûÂèØËÉΩ")) &&
                             i + 1 < tokens.size &&
                             tokens[i + 1].word == "„Å™„Åè" &&
                             tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂΩ¢ÂÆπË©û" &&
                             tokens[i + 1].startPosition <= currentToken.endPosition + 2
            
            // Check if this is the start of a compound noun sequence (consecutive nouns)
            val isCompoundNounStart = pos1_1 == "ÂêçË©û" && 
                                     i + 1 < tokens.size &&
                                     tokens[i + 1].kuromojiToken?.partOfSpeechLevel1 == "ÂêçË©û" &&
                                     tokens[i + 1].startPosition <= currentToken.endPosition + 2 &&
                                     // Only form compounds for certain patterns (avoid over-grouping)
                                     shouldFormCompoundNoun(currentToken, tokens, i)
            
            if (isShitara) {
                // Found „Åó„Åü + „Çâ - group them together to form „Åó„Åü„Çâ conditional
                val shitaToken = currentToken
                val raToken = tokens[i + 1]
                val combinedWord = shitaToken.word + raToken.word
                
                Log.d("SimplifiedGrouping", "‚úÖ Successfully grouping „Åó„Åü„Çâ: ${shitaToken.word} + ${raToken.word} ‚Üí $combinedWord")
                
                // For artificially split „Åó„Åü„Çâ tokens, we need to ensure the base form is "„Åô„Çã"
                val baseFormForLookup = if (shitaToken.baseForm == "„Åô„Çã") "„Åô„Çã" else currentKuromojiToken?.baseForm
                Log.d("SimplifiedGrouping", "  BaseForm for lookup: $baseFormForLookup (from shitaToken.baseForm=${shitaToken.baseForm}, currentToken.baseForm=${currentKuromojiToken?.baseForm})")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = shitaToken.startPosition,
                    endPosition = raToken.endPosition,
                    sequenceId = shitaToken.sequenceId,
                    kuromojiToken = currentKuromojiToken, // Keep verb's token info
                    baseForm = baseFormForLookup // Ensure base form is "„Åô„Çã" for dictionary lookup
                ))
                
                // Skip both tokens
                i += 2
            } else if (isDaredemo) {
                // Found Ë™∞ + „Åß + „ÇÇ or Ë™∞ + „Åß„ÇÇ - group them together to form Ë™∞„Åß„ÇÇ
                val dareToken = currentToken
                
                // Check if it's already grouped as „Åß„ÇÇ or separate „Åß + „ÇÇ
                if (i + 1 < tokens.size && tokens[i + 1].word == "„Åß„ÇÇ") {
                    // Already grouped as „Åß„ÇÇ
                    val demoToken = tokens[i + 1]
                    val combinedWord = dareToken.word + demoToken.word
                    
                    Log.d("SimplifiedGrouping", "Grouping Ë™∞„Åß„ÇÇ (pre-grouped): ${dareToken.word} + ${demoToken.word} ‚Üí $combinedWord")
                    
                    grouped.add(WordPosition(
                        word = combinedWord,
                        startPosition = dareToken.startPosition,
                        endPosition = demoToken.endPosition,
                        sequenceId = dareToken.sequenceId,
                        kuromojiToken = currentKuromojiToken // Keep Ë™∞'s token info
                    ))
                    
                    // Skip both tokens
                    i += 2
                } else if (i + 2 < tokens.size && tokens[i + 1].word == "„Åß" && tokens[i + 2].word == "„ÇÇ") {
                    // Separate „Åß + „ÇÇ
                    val deToken = tokens[i + 1]
                    val moToken = tokens[i + 2]
                    val combinedWord = dareToken.word + deToken.word + moToken.word
                    
                    Log.d("SimplifiedGrouping", "Grouping Ë™∞„Åß„ÇÇ (three parts): ${dareToken.word} + ${deToken.word} + ${moToken.word} ‚Üí $combinedWord")
                    
                    grouped.add(WordPosition(
                        word = combinedWord,
                        startPosition = dareToken.startPosition,
                        endPosition = moToken.endPosition,
                        sequenceId = dareToken.sequenceId,
                        kuromojiToken = currentKuromojiToken // Keep Ë™∞'s token info
                    ))
                    
                    // Skip all three tokens
                    i += 3
                } else {
                    // Shouldn't happen, but add the token as-is
                    grouped.add(currentToken)
                    i++
                }
            } else if (isToWaIe) {
                // Found „Å® + „ÅØ + „ÅÑ„Åà/Ë®Ä„Åà - group them together to form „Å®„ÅØ„ÅÑ„Åà
                val toToken = currentToken
                val waToken = tokens[i + 1]
                val ieToken = tokens[i + 2]
                val combinedWord = toToken.word + waToken.word + ieToken.word
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = toToken.startPosition,
                    endPosition = ieToken.endPosition,
                    sequenceId = toToken.sequenceId,
                    kuromojiToken = ieToken.kuromojiToken // Keep verb's token info as primary
                ))
                
                // Skip all three tokens
                i += 3
            } else if (isImaSugu) {
                // Found ‰ªä + „Åô„Åê - group them together to form ‰ªä„Åô„Åê
                val imaToken = currentToken
                val suguToken = tokens[i + 1]
                val combinedWord = imaToken.word + suguToken.word
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = imaToken.startPosition,
                    endPosition = suguToken.endPosition,
                    sequenceId = imaToken.sequenceId,
                    kuromojiToken = imaToken.kuromojiToken // Keep ‰ªä's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isShiyou) {
                // Found „Åó„Çà + „ÅÜ - group them together to form „Åó„Çà„ÅÜ volitional
                val shiyoToken = currentToken
                val uToken = tokens[i + 1]
                val combinedWord = shiyoToken.word + uToken.word
                
                Log.d("SimplifiedGrouping", "Grouping „Åó„Çà„ÅÜ volitional: ${shiyoToken.word} + ${uToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = shiyoToken.startPosition,
                    endPosition = uToken.endPosition,
                    sequenceId = shiyoToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep main verb's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isVolitionalSou) {
                // Found verb stem ending in „Åù + „ÅÜ - group them for volitional form (like Áõ¥„Åù„ÅÜ)
                val verbToken = currentToken
                val uToken = tokens[i + 1]
                val combinedWord = verbToken.word + uToken.word
                
                Log.d("SimplifiedGrouping", "Grouping volitional „Åù„ÅÜ: ${verbToken.word} + ${uToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = verbToken.startPosition,
                    endPosition = uToken.endPosition,
                    sequenceId = verbToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep verb's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isVolitionalRou) {
                // Found verb stem ending in „Çç + „ÅÜ - group them for volitional form (like Ëµ∞„Çç„ÅÜ)
                val verbToken = currentToken
                val uToken = tokens[i + 1]
                val combinedWord = verbToken.word + uToken.word
                
                Log.d("SimplifiedGrouping", "Grouping volitional „Çç„ÅÜ: ${verbToken.word} + ${uToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = verbToken.startPosition,
                    endPosition = uToken.endPosition,
                    sequenceId = verbToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep verb's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isYouNi) {
                // Found „Çà„ÅÜ + „Å´ - group them together to form „Çà„ÅÜ„Å´
                val youToken = currentToken
                val niToken = tokens[i + 1]
                val combinedWord = youToken.word + niToken.word
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = youToken.startPosition,
                    endPosition = niToken.endPosition,
                    sequenceId = youToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep „Çà„ÅÜ's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isToIu) {
                // Found „Å® + „ÅÑ„ÅÜ - group them together to form „Å®„ÅÑ„ÅÜ
                val toToken = currentToken
                val iuToken = tokens[i + 1]
                val combinedWord = toToken.word + iuToken.word
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = toToken.startPosition,
                    endPosition = iuToken.endPosition,
                    sequenceId = toToken.sequenceId,
                    kuromojiToken = iuToken.kuromojiToken // Keep „ÅÑ„ÅÜ's token info as it's the main word
                ))
                
                // Skip both tokens
                i += 2
            } else if (isDeWaNai) {
                // Found „Åß + „ÅØ + „Å™„ÅÑ - group them together to form „Åß„ÅØ„Å™„ÅÑ
                val deToken = currentToken
                val waToken = tokens[i + 1]
                val naiToken = tokens[i + 2]
                val combinedWord = deToken.word + waToken.word + naiToken.word
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = deToken.startPosition,
                    endPosition = naiToken.endPosition,
                    sequenceId = deToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep „Åß's token info
                ))
                
                // Skip all three tokens
                i += 3
            } else if (isDeMoNai) {
                // Found „Åß + „ÇÇ + „Å™„ÅÑ - group them together to form „Åß„ÇÇ„Å™„ÅÑ
                val deToken = currentToken
                val moToken = tokens[i + 1]
                val naiToken = tokens[i + 2]
                val combinedWord = deToken.word + moToken.word + naiToken.word
                
                Log.d("SimplifiedGrouping", "üî• EXECUTING Grouping „Åß„ÇÇ„Å™„ÅÑ at position $i: ${deToken.word} + ${moToken.word} + ${naiToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = deToken.startPosition,
                    endPosition = naiToken.endPosition,
                    sequenceId = deToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep „Åß's token info
                ))
                
                // Skip all three tokens
                i += 3
            } else if (isDeMo) {
                // Found „Åß + „ÇÇ - group them together to form „Åß„ÇÇ
                val deToken = currentToken
                val moToken = tokens[i + 1]
                val combinedWord = deToken.word + moToken.word
                
                Log.d("SimplifiedGrouping", "üî• EXECUTING Grouping „Åß„ÇÇ at position $i: ${deToken.word} + ${moToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = deToken.startPosition,
                    endPosition = moToken.endPosition,
                    sequenceId = deToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep „Åß's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isShitari) {
                // Found „Åó + „Åü„Çä - group them together to form „Åó„Åü„Çä
                val shiToken = currentToken
                val tariToken = tokens[i + 1]
                val combinedWord = shiToken.word + tariToken.word
                
                Log.d("SimplifiedGrouping", "Grouping „Åó„Åü„Çä: ${shiToken.word} + ${tariToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = shiToken.startPosition,
                    endPosition = tariToken.endPosition,
                    sequenceId = shiToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep verb's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isTariDariPattern) {
                // Found verb + „Åü„Çä/„Å†„Çä - group them together for listing pattern
                val verbToken = currentToken
                val tariToken = tokens[i + 1]
                val combinedWord = verbToken.word + tariToken.word
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = verbToken.startPosition,
                    endPosition = tariToken.endPosition,
                    sequenceId = verbToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep verb's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isAreba) {
                // Found „ÅÇ„Çå + „Å∞ - group them together to form „ÅÇ„Çå„Å∞ (conditional)
                val areToken = currentToken
                val baToken = tokens[i + 1]
                val combinedWord = areToken.word + baToken.word
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = areToken.startPosition,
                    endPosition = baToken.endPosition,
                    sequenceId = areToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep „ÅÇ„Çå's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isThreePartAdjective) {
                // Found ËâØ + „Åï + „Åù„ÅÜ - group all three together to form ËâØ„Åï„Åù„ÅÜ
                val adjToken = currentToken
                val saToken = tokens[i + 1]
                val souToken = tokens[i + 2]
                val combinedWord = adjToken.word + saToken.word + souToken.word
                
                Log.d("SimplifiedGrouping", "Grouping three-part adjective: ${adjToken.word} + ${saToken.word} + ${souToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = adjToken.startPosition,
                    endPosition = souToken.endPosition,
                    sequenceId = adjToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep adjective's token info
                ))
                
                // Skip all three tokens
                i += 3
            } else if (isAdjectiveWithSou) {
                // Found adjective stem + „Åù„ÅÜ - group them together (like ËâØ„Åï„Åù„ÅÜ)
                val adjectiveToken = currentToken
                val souToken = tokens[i + 1]
                val combinedWord = adjectiveToken.word + souToken.word
                
                Log.d("SimplifiedGrouping", "Grouping adjective + „Åù„ÅÜ: ${adjectiveToken.word} + ${souToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = adjectiveToken.startPosition,
                    endPosition = souToken.endPosition,
                    sequenceId = adjectiveToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep adjective's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isDemonstrativeWithJi) {
                // Found demonstrative pronoun + ÊôÇ - group them together
                val demonstrativeToken = currentToken
                val jiToken = tokens[i + 1]
                val combinedWord = demonstrativeToken.word + jiToken.word
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = demonstrativeToken.startPosition,
                    endPosition = jiToken.endPosition,
                    sequenceId = demonstrativeToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep demonstrative's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isVolitionalPart) {
                // Found „Å†„Çç/„Åæ„Åó„Çá + „ÅÜ - group them together to form „Å†„Çç„ÅÜ/„Åæ„Åó„Çá„ÅÜ
                val volitionalToken = currentToken
                val uToken = tokens[i + 1] 
                val combinedWord = volitionalToken.word + uToken.word
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = volitionalToken.startPosition,
                    endPosition = uToken.endPosition,
                    sequenceId = volitionalToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep volitional token's info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isConditional) {
                // Found verb + „Å∞ - group them together to form conditional
                val verbToken = currentToken
                val baToken = tokens[i + 1] 
                val combinedWord = verbToken.word + baToken.word
                
                // Get base form for dictionary lookup
                val baseFormForLookup = currentKuromojiToken.baseForm ?: verbToken.word
                
                Log.d("SimplifiedGrouping", "Grouping conditional: ${verbToken.word} + ${baToken.word} ‚Üí $combinedWord (baseForm: $baseFormForLookup)")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = verbToken.startPosition,
                    endPosition = baToken.endPosition,
                    sequenceId = verbToken.sequenceId,
                    kuromojiToken = currentKuromojiToken, // Keep verb token's info
                    baseForm = baseFormForLookup // Set base form for dictionary lookup
                ))
                
                // Skip both tokens
                i += 2
            } else if (isAdjectivePast) {
                // Found adjective stem + „Åü - group them together to form past tense
                val adjToken = currentToken
                val taToken = tokens[i + 1] 
                val combinedWord = adjToken.word + taToken.word
                
                // For adjectives like „Çà„Åã„Å£ + „Åü ‚Üí „Çà„ÅÑ/„ÅÑ„ÅÑ base form
                val baseFormForLookup = when {
                    currentKuromojiToken.baseForm != null -> currentKuromojiToken.baseForm
                    adjToken.word == "„Çà„Åã„Å£" -> "„Çà„ÅÑ"
                    adjToken.word.endsWith("„Åã„Å£") -> adjToken.word.dropLast(2) + "„ÅÑ" // General pattern: „Åã„Å£ ‚Üí „ÅÑ
                    else -> adjToken.word
                }
                
                Log.d("SimplifiedGrouping", "Grouping adjective past: ${adjToken.word} + ${taToken.word} ‚Üí $combinedWord (baseForm: $baseFormForLookup)")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = adjToken.startPosition,
                    endPosition = taToken.endPosition,
                    sequenceId = adjToken.sequenceId,
                    kuromojiToken = currentKuromojiToken, // Keep adjective token's info
                    baseForm = baseFormForLookup // Set base form for dictionary lookup
                ))
                
                // Skip both tokens
                i += 2
            } else if (isKiWoTsuke) {
                // Found Ê∞ó + „Çí + „Å§„Åë - group them together to form compound expression
                val kiToken = currentToken
                val woToken = tokens[i + 1] 
                val tsukeToken = tokens[i + 2]
                val combinedWord = kiToken.word + woToken.word + tsukeToken.word
                
                // Base form should be Ê∞ó„Çí„Å§„Åë„Çã for dictionary lookup
                val baseFormForLookup = "Ê∞ó„Çí„Å§„Åë„Çã"
                
                Log.d("SimplifiedGrouping", "Grouping compound: ${kiToken.word} + ${woToken.word} + ${tsukeToken.word} ‚Üí $combinedWord (baseForm: $baseFormForLookup)")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = kiToken.startPosition,
                    endPosition = tsukeToken.endPosition,
                    sequenceId = kiToken.sequenceId,
                    kuromojiToken = currentKuromojiToken, // Keep first token's info
                    baseForm = baseFormForLookup // Set base form for dictionary lookup
                ))
                
                // Skip all three tokens
                i += 3
            } else if (isAsaHayaku) {
                // Found Êúù + Êó©„Åè - group them together to form compound time expression
                val asaToken = currentToken
                val hayakuToken = tokens[i + 1] 
                val combinedWord = asaToken.word + hayakuToken.word
                
                // Base form should be ÊúùÊó©„Åè for dictionary lookup (it's an adverb compound)
                val baseFormForLookup = "ÊúùÊó©„Åè"
                
                Log.d("SimplifiedGrouping", "Grouping time compound: ${asaToken.word} + ${hayakuToken.word} ‚Üí $combinedWord (baseForm: $baseFormForLookup)")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = asaToken.startPosition,
                    endPosition = hayakuToken.endPosition,
                    sequenceId = asaToken.sequenceId,
                    kuromojiToken = currentKuromojiToken, // Keep first token's info
                    baseForm = baseFormForLookup // Set base form for dictionary lookup
                ))
                
                // Skip both tokens
                i += 2
            } else if (isUmakuIkiSou) {
                // Found „ÅÜ„Åæ„Åè + „ÅÑ„Åç + „Åù„ÅÜ - group them together to form compound expression
                val umakuToken = currentToken
                val ikiToken = tokens[i + 1] 
                val souToken = tokens[i + 2]
                val combinedWord = umakuToken.word + ikiToken.word + souToken.word
                
                // Base form should be „ÅÜ„Åæ„Åè„ÅÑ„Åè for dictionary lookup
                val baseFormForLookup = "„ÅÜ„Åæ„Åè„ÅÑ„Åè"
                
                Log.d("SimplifiedGrouping", "Grouping compound: ${umakuToken.word} + ${ikiToken.word} + ${souToken.word} ‚Üí $combinedWord (baseForm: $baseFormForLookup)")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = umakuToken.startPosition,
                    endPosition = souToken.endPosition,
                    sequenceId = umakuToken.sequenceId,
                    kuromojiToken = currentKuromojiToken, // Keep first token's info
                    baseForm = baseFormForLookup // Set base form for dictionary lookup
                ))
                
                // Skip all three tokens
                i += 3
            } else if (isKiWoTsukeyou) {
                // Found Ê∞ó + „Å§„Åë„Çà + „ÅÜ - group them together to form compound expression
                val kiToken = currentToken
                val tsukeyoToken = tokens[i + 1] 
                val uToken = tokens[i + 2]
                val combinedWord = kiToken.word + "„Çí" + tsukeyoToken.word + uToken.word
                
                // Base form should be Ê∞ó„Çí„Å§„Åë„Çã for dictionary lookup
                val baseFormForLookup = "Ê∞ó„Çí„Å§„Åë„Çã"
                
                Log.d("SimplifiedGrouping", "Grouping compound: ${kiToken.word} + „Çí + ${tsukeyoToken.word} + ${uToken.word} ‚Üí $combinedWord (baseForm: $baseFormForLookup)")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = kiToken.startPosition,
                    endPosition = uToken.endPosition,
                    sequenceId = kiToken.sequenceId,
                    kuromojiToken = currentKuromojiToken, // Keep first token's info
                    baseForm = baseFormForLookup // Set base form for dictionary lookup
                ))
                
                // Skip all three tokens
                i += 3
            } else if (isAdjectiveWithTe) {
                // Found adjective + „Å¶ - group them together (e.g., Áæé„Åó„Åè„Å¶)
                val adjectiveToken = currentToken
                val teToken = tokens[i + 1]
                val combinedWord = adjectiveToken.word + teToken.word
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = adjectiveToken.startPosition,
                    endPosition = teToken.endPosition,
                    sequenceId = adjectiveToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep adjective's token info
                ))
                
                // Skip both tokens
                i += 2
            } else if (isVerbStart) {
                // Found a verb that can start a group - start building verb group
                val verbGroup = mutableListOf<Pair<WordPosition, com.atilika.kuromoji.ipadic.Token>>()
                
                // Debug logging for verb starts, especially „Åô„Çã forms
                if (currentKuromojiToken.baseForm == "„Åô„Çã" || currentToken.word.contains("„Åï")) {
                    Log.d("SimplifiedGrouping", "Starting verb group with: ${currentToken.word} (${pos1_1},${pos1_2}) baseForm=${currentKuromojiToken.baseForm}")
                }
                
                verbGroup.add(Pair(currentToken, currentKuromojiToken))
                var j = i + 1
                
                // Check if this verb should be grouped with a following volitional form (like „Åæ„Åó„Çá„ÅÜ)
                var foundVolitional = false
                if (j < tokens.size) {
                    val nextToken = tokens[j]
                    val nextKuromojiToken = nextToken.kuromojiToken
                    if (nextKuromojiToken != null) {
                        val nextPos1 = nextKuromojiToken.partOfSpeechLevel1
                        // Check if next token is "„Åæ„Åó„Çá" that would be followed by "„ÅÜ"
                        if (nextToken.word == "„Åæ„Åó„Çá" && nextPos1 == "Âä©ÂãïË©û" && 
                            j + 1 < tokens.size && 
                            tokens[j + 1].word == "„ÅÜ" && 
                            tokens[j + 1].kuromojiToken?.partOfSpeechLevel1 == "Âä©ÂãïË©û" &&
                            nextToken.startPosition <= currentToken.endPosition + 2) {
                            
                            // Include both "„Åæ„Åó„Çá" and "„ÅÜ" in the verb group
                            verbGroup.add(Pair(nextToken, nextKuromojiToken))
                            verbGroup.add(Pair(tokens[j + 1], tokens[j + 1].kuromojiToken!!))
                            j += 2
                            foundVolitional = true
                            Log.d("SimplifiedGrouping", "Added volitional form to verb: ${currentToken.word} + ${nextToken.word} + ${tokens[j-1].word}")
                        }
                    }
                }
                
                // Look for consecutive auxiliary tokens (only if we didn't find a volitional form)
                if (!foundVolitional) {
                    while (j < tokens.size) {
                        val nextToken = tokens[j]
                        val nextKuromojiToken = nextToken.kuromojiToken ?: break
                        
                        // Check if tokens are adjacent
                        val isAdjacent = nextToken.startPosition <= verbGroup.last().first.endPosition + 2
                        if (!isAdjacent) break
                        
                        // Check if it's an auxiliary or verb suffix
                        if (isAuxiliaryOrVerbSuffix(nextKuromojiToken)) {
                            verbGroup.add(Pair(nextToken, nextKuromojiToken))
                            j++
                        } else {
                            break
                        }
                    }
                }
                
                // Create grouped token if we have more than just the main verb
                if (verbGroup.size > 1) {
                    val firstToken = verbGroup.first().first
                    val lastToken = verbGroup.last().first
                    val surfaceForm = verbGroup.joinToString("") { it.first.word }
                    
                    val baseForm = currentKuromojiToken.baseForm ?: currentToken.word
                    
                    // Debug logging for simplified grouping
                    if (surfaceForm.contains("Ë¶ã„Çâ„Çå„Åæ„Åõ„Çì") || surfaceForm.contains("ËÄÉ„Åà„Å¶„ÅÑ„Åæ„Åô") || 
                        surfaceForm.contains("Áô∫Ë°®„Åï„Çå") || surfaceForm.contains("„Åï„Çå„Åü") || 
                        surfaceForm.contains("„Åï") || baseForm == "„Åô„Çã" || surfaceForm.contains("„Åæ„Åó„Çá„ÅÜ")) {
                        Log.d("SimplifiedGrouping", "Grouped: $surfaceForm (base: $baseForm) from ${verbGroup.size} tokens")
                        verbGroup.forEach { (token, kuromojiToken) ->
                            Log.d("SimplifiedGrouping", "  - ${token.word} (${kuromojiToken.partOfSpeechLevel1},${kuromojiToken.partOfSpeechLevel2}) base=${kuromojiToken.baseForm}")
                        }
                    }
                    
                    grouped.add(WordPosition(
                        word = surfaceForm,
                        startPosition = firstToken.startPosition,
                        endPosition = lastToken.endPosition,
                        sequenceId = firstToken.sequenceId,
                        kuromojiToken = currentKuromojiToken, // Keep main verb's token info
                        baseForm = baseForm // Store the base form for proper dictionary lookup
                    ))
                } else {
                    // Single verb token, add as-is
                    grouped.add(currentToken)
                }
                
                // Skip all grouped tokens, accounting for compound verb start position
                i = j
            } else if (isNounForAgentSuffix) {
                // Found a noun followed by ËÄÖ - group them together
                val nounToken = currentToken
                val agentToken = tokens[i + 1]
                val combinedWord = nounToken.word + agentToken.word
                
                Log.d("SimplifiedGrouping", "Grouping noun + ËÄÖ: ${nounToken.word} + ${agentToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = nounToken.startPosition,
                    endPosition = agentToken.endPosition,
                    sequenceId = nounToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep noun's token info
                ))
                
                // Skip both the noun and ËÄÖ tokens
                i += 2
            } else if (isNounForSuffix) {
                // Found a noun followed by noun suffix - group them together
                val nounToken = currentToken
                val suffixToken = tokens[i + 1]
                val combinedWord = nounToken.word + suffixToken.word
                
                Log.d("SimplifiedGrouping", "Grouping noun + suffix: ${nounToken.word} + ${suffixToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = nounToken.startPosition,
                    endPosition = suffixToken.endPosition,
                    sequenceId = nounToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep main noun's token info
                ))
                
                // Skip both the noun and suffix tokens
                i += 2
            } else if (isPrefixForNoun) {
                // Found a prefix followed by noun - group them together
                val prefixToken = currentToken
                val nounToken = tokens[i + 1]
                val combinedWord = prefixToken.word + nounToken.word
                
                Log.d("SimplifiedGrouping", "Grouping prefix + noun: ${prefixToken.word} + ${nounToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = prefixToken.startPosition,
                    endPosition = nounToken.endPosition,
                    sequenceId = prefixToken.sequenceId,
                    kuromojiToken = nounToken.kuromojiToken // Keep noun's token info as primary
                ))
                
                // Skip both the prefix and noun tokens
                i += 2
            } else if (isYouNa) {
                // Found „Çà„ÅÜ followed by „Å™ - group them together to form „Çà„ÅÜ„Å™
                val youToken = currentToken
                val naToken = tokens[i + 1]
                val combinedWord = youToken.word + naToken.word
                
                Log.d("SimplifiedGrouping", "Grouping „Çà„ÅÜ + „Å™: ${youToken.word} + ${naToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = youToken.startPosition,
                    endPosition = naToken.endPosition,
                    sequenceId = youToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep „Çà„ÅÜ's token info
                ))
                
                // Skip both the „Çà„ÅÜ and „Å™ tokens
                i += 2
            } else if (isNounNaku) {
                // Found noun followed by „Å™„Åè - group them together and convert to dictionary form („Å™„ÅÑ)
                val nounToken = currentToken
                val nakuToken = tokens[i + 1]
                val combinedWord = nounToken.word + "„Å™„ÅÑ" // Use „Å™„ÅÑ (dictionary form) instead of „Å™„Åè
                
                Log.d("SimplifiedGrouping", "Grouping noun + „Å™„Åè: ${nounToken.word} + ${nakuToken.word} ‚Üí $combinedWord")
                
                grouped.add(WordPosition(
                    word = combinedWord,
                    startPosition = nounToken.startPosition,
                    endPosition = nakuToken.endPosition,
                    sequenceId = nounToken.sequenceId,
                    kuromojiToken = currentKuromojiToken // Keep noun's token info
                ))
                
                // Skip both the noun and „Å™„Åè tokens
                i += 2
            } else if (isCompoundNounStart) {
                // Found start of compound noun sequence - group consecutive technical nouns
                val compoundTokens = mutableListOf<Pair<WordPosition, com.atilika.kuromoji.ipadic.Token>>()
                compoundTokens.add(Pair(currentToken, currentKuromojiToken))
                
                var j = i + 1
                // Collect all consecutive technical nouns
                while (j < tokens.size) {
                    val nextToken = tokens[j]
                    val nextKuromojiToken = nextToken.kuromojiToken
                    
                    if (nextKuromojiToken != null &&
                        nextKuromojiToken.partOfSpeechLevel1 == "ÂêçË©û" &&
                        nextToken.startPosition <= compoundTokens.last().first.endPosition + 2 &&
                        shouldFormCompoundNoun(compoundTokens.last().first, tokens, j - 1)) {
                        
                        compoundTokens.add(Pair(nextToken, nextKuromojiToken))
                        j++
                    } else {
                        break
                    }
                }
                
                // Create compound if we have multiple tokens
                if (compoundTokens.size > 1) {
                    val firstToken = compoundTokens.first().first
                    val lastToken = compoundTokens.last().first
                    val compoundWord = compoundTokens.joinToString("") { it.first.word }
                    
                    Log.d("SimplifiedGrouping", "Grouping compound noun: ${compoundTokens.map { it.first.word }.joinToString("+")} ‚Üí $compoundWord")
                    
                    grouped.add(WordPosition(
                        word = compoundWord,
                        startPosition = firstToken.startPosition,
                        endPosition = lastToken.endPosition,
                        sequenceId = firstToken.sequenceId,
                        kuromojiToken = currentKuromojiToken // Keep first noun's token info
                    ))
                    
                    i = j // Skip all compound tokens
                } else {
                    // Single noun, add as-is
                    grouped.add(currentToken)
                    i++
                }
            } else {
                // Not a main verb, noun+ËÄÖ, noun+suffix, prefix+noun, noun+„Å™„Åè, compound noun, or „Çà„ÅÜ+„Å™, add as single token
                if (currentToken.word == "„Åß") {
                    val nextWord = if (i + 1 < tokens.size) tokens[i + 1].word else "END"
                    Log.d("SimplifiedGrouping", "‚ö†Ô∏è „Åß token at position $i falling through to single token processing: „Åß ‚Üí $nextWord")
                }
                grouped.add(currentToken)
                i++
            }
        }
        
        return grouped
    }
    
    /**
     * Check if consecutive nouns should form a compound noun
     * This is conservative to avoid over-grouping common words
     */
    private fun shouldFormCompoundNoun(currentToken: WordPosition, tokens: List<WordPosition>, currentIndex: Int): Boolean {
        val currentWord = currentToken.word
        val nextWord = if (currentIndex + 1 < tokens.size) tokens[currentIndex + 1].word else ""
        
        // Specific compound patterns that should be grouped
        val validCompounds = setOf(
            "Â§™ÈôΩ" to "ÈõªÊ±†",    // solar battery
            "ÈõªÊ±†" to "„Éë„Éç„É´",  // battery panel  
            "Â§™ÈôΩÈõªÊ±†" to "„Éë„Éç„É´", // solar battery panel (if already formed)
            "„Çπ„Ç±„Éº„É´" to "„Ç¢„ÉÉ„Éó",  // scale up
            "ÂèØËÉΩ" to "ÊÄß"       // possibility
        )
        
        // Check if this specific pair should form a compound
        return validCompounds.contains(currentWord to nextWord)
    }

    /**
     * Check if a token is an auxiliary verb or verb suffix that should be grouped with a main verb
     */
    private fun isAuxiliaryOrVerbSuffix(token: com.atilika.kuromoji.ipadic.Token): Boolean {
        val pos1 = token.partOfSpeechLevel1
        val pos2 = token.partOfSpeechLevel2
        val surface = token.surface
        val baseForm = token.baseForm
        
        // Special handling for volitional forms - these components will be grouped by special logic above
        // So they should not be treated as auxiliary verbs for general grouping
        if ((surface == "„Å†„Çç" && baseForm == "„Å†") || 
            (surface == "„Åæ„Åó„Çá" && baseForm == "„Åæ„Åô") ||
            (surface == "„ÅÜ" && baseForm == "„ÅÜ")) {
            return false // Don't group these as general auxiliaries - they have special handling
        }
        
        // Certain ÈùûËá™Á´ã verbs should be treated as independent verbs, not auxiliaries
        val independentNonJirituVerbs = setOf("Á∂ö„Åë„Çã", "Âßã„ÇÅ„Çã", "ÁµÇ„Åà„Çã", "Âá∫„Åô", "Ëæº„ÇÄ", "‰∏ä„Åå„Çã", "‰∏ã„Åå„Çã")
        if (pos1 == "ÂãïË©û" && pos2 == "ÈùûËá™Á´ã" && independentNonJirituVerbs.contains(baseForm)) {
            return false // Treat these as independent verbs
        }
        
        return pos1 == "Âä©ÂãïË©û" || // Auxiliary verbs: „Åæ„Åô, „Å™„ÅÑ, „Åü, etc.
               (pos1 == "ÂãïË©û" && pos2 == "Êé•Â∞æ") || // Verb suffixes: „Çâ„Çå, „Åõ, etc.
               (pos1 == "ÂãïË©û" && pos2 == "ÈùûËá™Á´ã") || // Non-independent verbs: „ÅÑ„Çã in „Å¶„ÅÑ„Çã
               (pos1 == "Âä©Ë©û" && surface == "„Å¶") // Te particle (for continuous forms)
    }

    
    // ===== NEW RULE-BASED SYSTEM =====
    
    /**
     * NEW RULE-BASED SYSTEM: Determine if two adjacent tokens should be grouped together
     * Rules are ordered by specificity (most specific first) to prevent conflicts
     */
    private fun shouldGroupTokensNew(
        token1: com.atilika.kuromoji.ipadic.Token,
        token2: com.atilika.kuromoji.ipadic.Token,
        wordPos1: WordPosition,
        wordPos2: WordPosition
    ): Boolean {
        // Apply rules in priority order (most specific to most general)
        return shouldGroupByTeForm(token1, token2, wordPos1, wordPos2) ||
               shouldGroupVerbWithSuffix(token1, token2, wordPos1, wordPos2) ||
               shouldGroupAdjectiveConjugation(token1, token2, wordPos1, wordPos2) ||
               shouldGroupVerbWithAuxiliary(token1, token2, wordPos1, wordPos2) ||
               shouldGroupAuxiliaryChain(token1, token2, wordPos1, wordPos2)
    }
    
    /**
     * RULE 1: Te-form Grouping (Highest Priority)
     * Handles: verb + „Å¶, „Å¶ + auxiliary patterns
     */
    private fun shouldGroupByTeForm(
        token1: com.atilika.kuromoji.ipadic.Token,
        token2: com.atilika.kuromoji.ipadic.Token,
        wordPos1: WordPosition,
        wordPos2: WordPosition
    ): Boolean {
        val pos1_1 = token1.partOfSpeechLevel1
        val pos1_2 = token1.partOfSpeechLevel2 
        val pos1_6 = token1.conjugationForm
        val pos2_1 = token2.partOfSpeechLevel1
        val pos2_2 = token2.partOfSpeechLevel2
        
        // Rule 1a: Verb (ÈÄ£Áî®ÂΩ¢ or ÈÄ£Áî®„ÇøÊé•Á∂ö) + „Å¶ particle
        if (pos1_1 == "ÂãïË©û" && pos1_2 == "Ëá™Á´ã" && 
            (pos1_6 == "ÈÄ£Áî®ÂΩ¢" || pos1_6 == "ÈÄ£Áî®„ÇøÊé•Á∂ö") &&
            wordPos2.word == "„Å¶" && pos2_1 == "Âä©Ë©û") {
            return true
        }
        
        // Rule 1b: „Å¶ particle + auxiliary verb („ÅÑ„Çã/„ÅÇ„Çã/„ÅÑ„Åè etc.)
        if (wordPos1.word == "„Å¶" && pos1_1 == "Âä©Ë©û" &&
            pos2_1 == "ÂãïË©û" && pos2_2 == "ÈùûËá™Á´ã") {
            return true
        }
        
        // Rule 1c: „Å¶ particle + „ÅÑ (continuous form fragment)
        if (wordPos1.word == "„Å¶" && pos1_1 == "Âä©Ë©û" &&
            wordPos2.word == "„ÅÑ" && pos2_1 == "ÂãïË©û") {
            return true
        }
        
        // Rule 1d: „Å¶ + polite auxiliary („Åæ„Åô/„Åß„Åô forms)
        if (wordPos1.word == "„Å¶" && pos1_1 == "Âä©Ë©û" &&
            pos2_1 == "Âä©ÂãïË©û" && isPoliteAuxiliary(wordPos2.word)) {
            return true
        }
        
        return false
    }
    
    /**
     * RULE 2: Verb + Verb Suffix (High Priority)
     * Handles: passive/potential „Çâ„Çå, causative „Åï„Åõ patterns
     */
    private fun shouldGroupVerbWithSuffix(
        token1: com.atilika.kuromoji.ipadic.Token,
        token2: com.atilika.kuromoji.ipadic.Token,
        wordPos1: WordPosition,
        wordPos2: WordPosition
    ): Boolean {
        val pos1_1 = token1.partOfSpeechLevel1
        val pos1_2 = token1.partOfSpeechLevel2
        val pos1_6 = token1.conjugationForm
        val pos2_1 = token2.partOfSpeechLevel1
        val pos2_2 = token2.partOfSpeechLevel2
        
        // Rule 2a: Verb Êú™ÁÑ∂ÂΩ¢ + „Çâ„Çå (passive/potential)
        if (pos1_1 == "ÂãïË©û" && pos1_2 == "Ëá™Á´ã" && pos1_6 == "Êú™ÁÑ∂ÂΩ¢" &&
            pos2_1 == "ÂãïË©û" && pos2_2 == "Êé•Â∞æ" && wordPos2.word == "„Çâ„Çå") {
            return true
        }
        
        // Rule 2b: Verb suffix + auxiliary („Çâ„Çå + „Åæ„Åõ etc.)
        if (pos1_1 == "ÂãïË©û" && pos1_2 == "Êé•Â∞æ" &&
            pos2_1 == "Âä©ÂãïË©û" && isCompatibleWithVerbSuffix(wordPos1.word, wordPos2.word)) {
            return true
        }
        
        return false
    }
    
    /**
     * RULE 3: Adjective Conjugations (Medium Priority) - NEW!
     * Handles: „ÅÑ-adjectives + „Å™„ÅÑ, adjective stems + auxiliary
     */
    private fun shouldGroupAdjectiveConjugation(
        token1: com.atilika.kuromoji.ipadic.Token,
        token2: com.atilika.kuromoji.ipadic.Token,
        wordPos1: WordPosition,
        wordPos2: WordPosition
    ): Boolean {
        val pos1_1 = token1.partOfSpeechLevel1
        val pos1_2 = token1.partOfSpeechLevel2
        val pos2_1 = token2.partOfSpeechLevel1
        val pos2_2 = token2.partOfSpeechLevel2
        
        // Rule 3a: „ÅÑ-adjective + „Å™„ÅÑ (negative forms)
        if (pos1_1 == "ÂΩ¢ÂÆπË©û" && pos1_2 == "Ëá™Á´ã" &&
            ((pos2_1 == "Âä©ÂãïË©û" && wordPos2.word == "„Å™„ÅÑ") ||
             (pos2_1 == "ÂΩ¢ÂÆπË©û" && pos2_2 == "Ëá™Á´ã" && wordPos2.word == "„Å™„ÅÑ"))) {
            return true
        }
        
        // Rule 3b: Adjective stem + auxiliary/verb (Â§ß„Åç„Åè + „Å™„Çã etc.)
        if (pos1_1 == "ÂΩ¢ÂÆπË©û" && pos1_2 == "Ëá™Á´ã" && 
            (pos2_1 == "Âä©ÂãïË©û" || pos2_1 == "ÂãïË©û") &&
            isCompatibleWithAdjective(wordPos1.word, wordPos2.word)) {
            return true
        }
        
        return false
    }
    
    /**
     * RULE 4: Verb Stem + Compatible Auxiliary (Medium-Low Priority)
     * Handles: basic polite forms, tense markers
     */
    private fun shouldGroupVerbWithAuxiliary(
        token1: com.atilika.kuromoji.ipadic.Token,
        token2: com.atilika.kuromoji.ipadic.Token,
        wordPos1: WordPosition,
        wordPos2: WordPosition
    ): Boolean {
        val pos1_1 = token1.partOfSpeechLevel1
        val pos1_2 = token1.partOfSpeechLevel2
        val pos1_6 = token1.conjugationForm
        val pos2_1 = token2.partOfSpeechLevel1
        
        // Rule 4a: Main verb stem + compatible auxiliary based on conjugation form
        if (pos1_1 == "ÂãïË©û" && pos1_2 == "Ëá™Á´ã" && pos2_1 == "Âä©ÂãïË©û" &&
            isVerbAuxiliaryCompatible(pos1_6, wordPos2.word)) {
            return true
        }
        
        // Rule 4b: Auxiliary verb + compatible auxiliary (like „ÅÑ + „Åæ„Åô)
        if (pos1_1 == "ÂãïË©û" && pos1_2 == "ÈùûËá™Á´ã" && pos2_1 == "Âä©ÂãïË©û" &&
            isAuxiliaryVerbCompatible(wordPos1.word, wordPos2.word)) {
            return true
        }
        
        return false
    }
    
    /**
     * RULE 5: Chained Auxiliaries (Lowest Priority)
     * Handles: auxiliary + auxiliary patterns
     */
    private fun shouldGroupAuxiliaryChain(
        token1: com.atilika.kuromoji.ipadic.Token,
        token2: com.atilika.kuromoji.ipadic.Token,
        wordPos1: WordPosition,
        wordPos2: WordPosition
    ): Boolean {
        val pos1_1 = token1.partOfSpeechLevel1
        val pos2_1 = token2.partOfSpeechLevel1
        
        // Rule 5a: Auxiliary + auxiliary chains
        if (pos1_1 == "Âä©ÂãïË©û" && pos2_1 == "Âä©ÂãïË©û" &&
            isAuxiliaryChainValid(wordPos1.word, wordPos2.word)) {
            return true
        }
        
        return false
    }
    
    // ===== COMPATIBILITY VALIDATION FUNCTIONS =====
    
    private fun isPoliteAuxiliary(word: String): Boolean {
        return word.startsWith("„Åæ") || word == "„Åß„Åô"
    }
    
    private fun isCompatibleWithVerbSuffix(suffix: String, auxiliary: String): Boolean {
        return when (suffix) {
            "„Çâ„Çå" -> auxiliary in setOf("„Åæ„Åô", "„Åæ„Åõ", "„Åü", "„Å™„ÅÑ")
            else -> false
        }
    }
    
    private fun isCompatibleWithAdjective(adjective: String, auxiliary: String): Boolean {
        return when {
            adjective.endsWith("„Åè") -> auxiliary in setOf("„Å™„ÅÑ", "„Å™„Çã", "„Åô„Çã")
            else -> false
        }
    }
    
    private fun isVerbAuxiliaryCompatible(conjugationForm: String?, auxiliary: String): Boolean {
        return when (conjugationForm) {
            "ÈÄ£Áî®ÂΩ¢" -> auxiliary in setOf("„Åæ„Åô", "„Åæ„Åó", "„Åü", "„Å¶", "„Åæ„Åõ", "„Åü„ÅÑ", "„Åü„Åè")
            "Êú™ÁÑ∂ÂΩ¢" -> auxiliary in setOf("„Å™„ÅÑ", "„Å™„Åã„Å£", "„Çå„Çã", "„Çâ„Çå„Çã", "„Åõ„Çã", "„Åï„Åõ„Çã")
            "Âü∫Êú¨ÂΩ¢" -> auxiliary in setOf("„Å†", "„Åß„Åô", "„Åß„Åó„Çá„ÅÜ")
            else -> auxiliary in setOf("„Åæ„Åô", "„Å†", "„Åß„Åô", "„Åü") // Default safe auxiliaries
        }
    }
    
    private fun isAuxiliaryChainValid(aux1: String, aux2: String): Boolean {
        return when (aux1) {
            "„Åæ„Åó" -> aux2 == "„Åü"
            "„Åæ„Åõ" -> aux2 in setOf("„Çì", "„Çì„Åß")
            "„Å™„Åã„Å£" -> aux2 == "„Åü"
            "„Åü„Åè" -> aux2 == "„Å™„ÅÑ"
            else -> false
        }
    }
    
    private fun isAuxiliaryVerbCompatible(auxVerb: String, auxiliary: String): Boolean {
        return when (auxVerb) {
            "„ÅÑ" -> auxiliary in setOf("„Åæ„Åô", "„Åæ„Åó", "„Åæ„Åõ", "„Åü", "„Å†", "„Åß„Åô") // continuous form auxiliary
            "„ÅÇ„Çã" -> auxiliary in setOf("„Åæ„Åô", "„Åæ„Åó", "„Åæ„Åõ", "„Å†", "„Åß„Åô") // existence auxiliary
            "„ÅÑ„Çã" -> auxiliary in setOf("„Åæ„Åô", "„Åæ„Åó", "„Åæ„Åõ", "„Å†", "„Åß„Åô") // continuous existence
            else -> false
        }
    }

    /**
     * Split compound words separated by middle dot („Éª) into individual words
     * Example: "„Ç®„É¨„ÇØ„Éà„É≠„Éã„ÉÉ„ÇØ„Éª„ÉÜ„Ç≠„Çπ„Éà„Éª„Çª„É≥„Çø„Éº" -> "„Ç®„É¨„ÇØ„Éà„É≠„Éã„ÉÉ„ÇØ|„ÉÜ„Ç≠„Çπ„Éà|„Çª„É≥„Çø„Éº"
     * Using | as a temporary marker that won't be removed by reconnectJapaneseWords
     */
    private fun splitCompoundWords(text: String): String {
        // Replace middle dot with pipe character as temporary marker
        return text.replace("„Éª", "|")
    }
    
    /**
     * Remove spaces within Japanese words that were incorrectly split by OCR
     * Example: "Ëºù„Åã „Åó„ÅÑ" -> "Ëºù„Åã„Åó„ÅÑ"
     */
    private fun reconnectJapaneseWords(text: String): String {
        val result = StringBuilder()
        var i = 0
        
        while (i < text.length) {
            val char = text[i]
            
            // If current char is a pipe marker (word boundary), convert to space
            if (char == '|') {
                result.append(' ')
                i++
            }
            // If current char is Japanese
            else if (JAPANESE_CHAR.matches(char.toString())) {
                result.append(char)
                i++
                
                // Look ahead and skip any whitespace (including line breaks) between Japanese characters
                while (i < text.length && isWhitespaceOrLineBreak(text[i])) {
                    val nextNonSpace = findNextNonSpace(text, i)
                    if (nextNonSpace != -1 && JAPANESE_CHAR.matches(text[nextNonSpace].toString())) {
                        // Skip the whitespace/line break - they're within a Japanese word
                        i = nextNonSpace
                    } else {
                        // Keep the space - it's between Japanese and non-Japanese
                        result.append(' ') // Normalize to regular space
                        i++
                        break
                    }
                }
            } else {
                // Non-Japanese character, keep as-is
                result.append(char)
                i++
            }
        }
        
        return result.toString()
    }
    
    /**
     * Check if character is whitespace or line break (including full-width spaces)
     */
    private fun isWhitespaceOrLineBreak(char: Char): Boolean {
        return char.isWhitespace() || char == '\u3000' || char == '\n' || char == '\r'
    }
    
    /**
     * Find the next non-whitespace character position (including full-width spaces and line breaks)
     */
    private fun findNextNonSpace(text: String, startPos: Int): Int {
        for (i in startPos until text.length) {
            if (!isWhitespaceOrLineBreak(text[i])) {
                return i
            }
        }
        return -1
    }
    
    /**
     * Find the next occurrence of a token in text, with better position tracking
     * This addresses issues with multiple identical tokens getting wrong positions
     */
    private fun findTokenPosition(text: String, surface: String, startPosition: Int): Int {
        var searchPos = startPosition
        while (searchPos < text.length) {
            val foundPos = text.indexOf(surface, searchPos)
            if (foundPos == -1) return -1
            
            // Check if this occurrence makes sense contextually
            // For now, just return the first occurrence after startPosition
            if (foundPos >= startPosition) {
                return foundPos
            }
            searchPos = foundPos + 1
        }
        return -1
    }
    
    /**
     * Map a position from processed text back to original text
     * Build a character-by-character mapping to ensure accuracy
     */
    private fun mapProcessedPositionToOriginal(originalText: String, processedText: String, processedPos: Int, surface: String): Int {
        // If texts are identical, positions map directly
        if (originalText == processedText) {
            return processedPos
        }
        
        // For complex cases, use the simple approach if processed and original are similar
        // This fixes the issue where character mapping gets confused with multiple identical tokens
        if (processedPos >= 0 && processedPos + surface.length <= processedText.length) {
            val processedSurface = processedText.substring(processedPos, processedPos + surface.length)
            if (processedSurface == surface && processedPos + surface.length <= originalText.length) {
                val originalSurface = originalText.substring(processedPos, processedPos + surface.length)
                if (originalSurface == surface) {
                    // Debug logging for position mapping fixes
                    if (surface.contains("Âêç‰ªò„Åë") || (surface == "„Åü" && processedText.contains("Âêç‰ªò„Åë"))) {
                        Log.d("PositionMap", "Direct position mapping for '$surface': $processedPos -> $processedPos")
                    }
                    return processedPos
                }
            }
        }
        
        // Build character mapping between processed and original text
        val mapping = buildPositionMapping(originalText, processedText)
        
        // Map the processed position to original position
        val originalPos = if (processedPos < mapping.size) {
            mapping[processedPos]
        } else {
            -1
        }
        
        // Verify the mapping is correct by checking if surface text matches
        if (originalPos >= 0 && originalPos + surface.length <= originalText.length) {
            val originalSurface = originalText.substring(originalPos, originalPos + surface.length)
            if (originalSurface == surface) {
                // Debug logging for complex mapping
                if (surface.contains("Âêç‰ªò„Åë") || (surface == "„Åü" && processedText.contains("Âêç‰ªò„Åë"))) {
                    Log.d("PositionMap", "Complex position mapping for '$surface': $processedPos -> $originalPos")
                }
                return originalPos
            }
        }
        
        // If mapping failed, fall back to search but log the issue
        if (surface.contains("Âêç‰ªò„Åë") || (surface == "„Åü" && processedText.contains("Âêç‰ªò„Åë"))) {
            Log.w("PositionMap", "Mapping failed for '$surface' at processed pos $processedPos, falling back to search")
        }
        return originalText.indexOf(surface)
    }
    
    /**
     * Check if an auxiliary verb is part of a compound expression
     */
    private fun checkIfAuxiliaryIsPartOfCompound(
        surface: String, 
        tokens: List<com.atilika.kuromoji.ipadic.Token>, 
        currentIndex: Int, 
        pos1: String
    ): Boolean {
        when (surface) {
            "„Åß" -> {
                // Keep „Åß only if followed by „ÅØ+„Å™„ÅÑ (for „Åß„ÅØ„Å™„ÅÑ) or „ÇÇ (for „Åß„ÇÇ)
                if (currentIndex + 1 < tokens.size) {
                    val nextToken = tokens[currentIndex + 1]
                    if (nextToken.surface == "„ÇÇ") {
                        return true // Keep for „Åß„ÇÇ
                    }
                    // Keep „Åß only if followed by „ÅØ AND then „Å™„ÅÑ (for „Åß„ÅØ„Å™„ÅÑ)
                    if (nextToken.surface == "„ÅØ" && currentIndex + 2 < tokens.size) {
                        val thirdToken = tokens[currentIndex + 2]
                        if (thirdToken.surface == "„Å™„ÅÑ") {
                            return true // Keep for „Åß„ÅØ„Å™„ÅÑ
                        }
                    }
                    // Don't keep „Åß for standalone „Åß„ÅØ
                }
            }
        }
        return false
    }
    
    /**
     * Check if a particle is part of a compound expression that should be grouped
     */
    private fun checkIfPartOfCompound(
        surface: String, 
        tokens: List<com.atilika.kuromoji.ipadic.Token>, 
        currentIndex: Int, 
        pos1: String
    ): Boolean {
        // Check for particles that are part of compound expressions
        when (surface) {
            "„Å´" -> {
                // Keep „Å´ if preceded by „Çà„ÅÜ to form „Çà„ÅÜ„Å´
                if (currentIndex > 0) {
                    val prevToken = tokens[currentIndex - 1]
                    if (prevToken.surface == "„Çà„ÅÜ" && prevToken.partOfSpeechLevel1 == "ÂêçË©û") {
                        return true
                    }
                }
            }
            "„Åß" -> {
                // Keep „Åß only if followed by „ÅØ+„Å™„ÅÑ (for „Åß„ÅØ„Å™„ÅÑ) or „ÇÇ (for „Åß„ÇÇ)
                if (currentIndex + 1 < tokens.size) {
                    val nextToken = tokens[currentIndex + 1]
                    if (nextToken.surface == "„ÇÇ") {
                        return true // Keep for „Åß„ÇÇ
                    }
                    // Keep „Åß only if followed by „ÅØ AND then „Å™„ÅÑ (for „Åß„ÅØ„Å™„ÅÑ)
                    if (nextToken.surface == "„ÅØ" && currentIndex + 2 < tokens.size) {
                        val thirdToken = tokens[currentIndex + 2]
                        if (thirdToken.surface == "„Å™„ÅÑ") {
                            return true // Keep for „Åß„ÅØ„Å™„ÅÑ
                        }
                    }
                    // Don't keep „Åß for standalone „Åß„ÅØ
                }
                // Keep „Åß if preceded by Ë™∞ and followed by „ÇÇ to form Ë™∞„Åß„ÇÇ
                if (currentIndex > 0 && currentIndex + 1 < tokens.size) {
                    val prevToken = tokens[currentIndex - 1]
                    val nextToken = tokens[currentIndex + 1]
                    if (prevToken.surface == "Ë™∞" && prevToken.partOfSpeechLevel1 == "ÂêçË©û" &&
                        nextToken.surface == "„ÇÇ") {
                        return true
                    }
                }
            }
            "„ÅØ" -> {
                // Keep „ÅØ only if it's part of specific patterns
                if (currentIndex > 0) {
                    val prevToken = tokens[currentIndex - 1]
                    
                    // Keep „ÅØ if preceded by „Åß AND followed by „Å™„ÅÑ to form „Åß„ÅØ„Å™„ÅÑ
                    if (prevToken.surface == "„Åß" && currentIndex + 1 < tokens.size) {
                        val nextToken = tokens[currentIndex + 1]
                        if (nextToken.surface == "„Å™„ÅÑ") {
                            return true // Keep for „Åß„ÅØ„Å™„ÅÑ pattern
                        }
                        // Don't keep „ÅØ for standalone „Åß„ÅØ (will be filtered out)
                        return false
                    }
                    
                    // Keep „ÅØ if preceded by „Å® to form „Å®„ÅØ (for „Å®„ÅØ„ÅÑ„Åà pattern)
                    if (prevToken.surface == "„Å®" && prevToken.partOfSpeechLevel1 == "Âä©Ë©û") {
                        return true
                    }
                }
            }
            "„ÇÇ" -> {
                // Keep „ÇÇ if preceded by „Åß to form „Åß„ÇÇ (check both auxiliary and particle „Åß)
                if (currentIndex > 0) {
                    val prevToken = tokens[currentIndex - 1]
                    if (prevToken.surface == "„Åß") {
                        return true // Always keep „ÇÇ after „Åß to form „Åß„ÇÇ
                    }
                    // Also keep „ÇÇ if it's part of Ë™∞„Åß„ÇÇ pattern
                    if (currentIndex > 1 && 
                        prevToken.surface == "„Åß" && 
                        tokens[currentIndex - 2].surface == "Ë™∞") {
                        return true
                    }
                }
            }
            "„Å®" -> {
                // Keep „Å® if followed by „ÅÑ„ÅÜ, or „ÅØ+„ÅÑ„Åà (for „Å®„ÅØ„ÅÑ„Åà pattern)
                if (currentIndex + 1 < tokens.size) {
                    val nextToken = tokens[currentIndex + 1]
                    if (nextToken.surface == "„ÅÑ„ÅÜ" && nextToken.partOfSpeechLevel1 == "ÂãïË©û") {
                        return true
                    }
                    // Check for „Å®„ÅØ„ÅÑ„Åà pattern („Å®+„ÅØ+„ÅÑ„Åà)
                    if (nextToken.surface == "„ÅØ" && currentIndex + 2 < tokens.size) {
                        val thirdToken = tokens[currentIndex + 2]
                        if ((thirdToken.surface == "Ë®Ä„Åà" || thirdToken.surface == "„ÅÑ„Åà") && 
                            thirdToken.partOfSpeechLevel1 == "ÂãïË©û") {
                            return true
                        }
                    }
                }
            }
            "„Çâ" -> {
                // Keep „Çâ if preceded by „Åó„Åü to form „Åó„Åü„Çâ conditional
                if (currentIndex > 0) {
                    val prevToken = tokens[currentIndex - 1]
                    if (prevToken.surface == "„Åó„Åü" || 
                        (prevToken.surface == "„Åó" && prevToken.baseForm == "„Åô„Çã")) {
                        return true
                    }
                }
            }
        }
        return false
    }

    /**
     * Build a mapping array from processed text positions to original text positions
     */
    private fun buildPositionMapping(originalText: String, processedText: String): IntArray {
        val mapping = IntArray(processedText.length) { -1 }
        var originalPos = 0
        var processedPos = 0
        
        while (originalPos < originalText.length && processedPos < processedText.length) {
            val originalChar = originalText[originalPos]
            val processedChar = processedText[processedPos]
            
            if (originalChar == processedChar) {
                // Characters match - direct mapping
                mapping[processedPos] = originalPos
                originalPos++
                processedPos++
            } else if (isWhitespaceOrLineBreak(originalChar)) {
                // Original has whitespace/line break that was removed in processed text
                originalPos++
            } else if (processedChar.isWhitespace()) {
                // Processed has whitespace that wasn't in original (shouldn't happen with our logic)
                processedPos++
            } else {
                // Characters don't match - try to align
                mapping[processedPos] = originalPos
                originalPos++
                processedPos++
            }
        }
        
        return mapping
    }
    
}